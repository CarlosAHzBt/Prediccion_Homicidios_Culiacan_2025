â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                              â•‘
â•‘           âœ… CONFIGURACIÃ“N PERSONALIZADA COMPLETADA                          â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“‹ TU CONFIGURACIÃ“N:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“… PerÃ­odo: 2024-09-01 â†’ 2025-09-30 (13 meses, 395 dÃ­as)

ğŸ“ Palabras clave:
   â€¢ Culiacan
   â€¢ CuliacÃ¡n  
   â€¢ Culiacan Sinaloa

ğŸ’¬ Incluye:
   âœ“ Tweets base
   âœ“ Respuestas (replies)

ğŸš« Excluye:
   âœ— Retweets

ğŸŒ Idioma: EspaÃ±ol (es)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š ESTADÃSTICAS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Total de dÃ­as a recolectar: 395
Tiempo estimado: 6-7 horas
Archivos a generar: 395 archivos .jsonl

Desglose por mes:
  â€¢ Sep 2024: 30 dÃ­as
  â€¢ Oct 2024: 31 dÃ­as
  â€¢ Nov 2024: 30 dÃ­as
  â€¢ Dic 2024: 31 dÃ­as
  â€¢ Ene 2025: 31 dÃ­as
  â€¢ Feb 2025: 28 dÃ­as
  â€¢ Mar 2025: 31 dÃ­as
  â€¢ Abr 2025: 30 dÃ­as
  â€¢ May 2025: 31 dÃ­as
  â€¢ Jun 2025: 30 dÃ­as
  â€¢ Jul 2025: 31 dÃ­as
  â€¢ Ago 2025: 31 dÃ­as
  â€¢ Sep 2025: 30 dÃ­as

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸš€ CÃ“MO EJECUTAR (OPCIÃ“N 1 - RECOMENDADA):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

PASO 1: Instalar snscrape (si no lo tienes)

    pip install snscrape

    O si da problemas:

    pip install git+https://github.com/JustAnotherArchivist/snscrape.git


PASO 2: Ejecutar el script de recolecciÃ³n

    cd utils\scrapping
    .\recolectar_tweets_culiacan.ps1


PASO 3: Esperar (6-7 horas)

    El script mostrarÃ¡ el progreso:
    [1/395] Recolectando 2024-09-01...
    [2/395] Recolectando 2024-09-02...
    ...

    ğŸ’¡ Puedes pausar con Ctrl+C y reanudar despuÃ©s


PASO 4: Una vez completada la recolecciÃ³n, procesar los datos

    cd ..\..  # Volver a la raÃ­z del proyecto
    
    # Primero instalar dependencias
    pip install -r utils\scrapping\requirements_tweets.txt
    
    # Luego ejecutar el procesamiento
    python utils\scrapping\ejemplo_uso_completo.py
    
    # Seleccionar:
    # OpciÃ³n 3: Procesar tweets recolectados
    # OpciÃ³n 4: Generar visualizaciones

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸš€ OPCIÃ“N 2 - EJECUCIÃ“N MANUAL (DÃA POR DÃA):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Si prefieres hacerlo manual o probar con un solo dÃ­a primero:

# Crear directorio (solo la primera vez)
New-Item -ItemType Directory -Path "data_tweets_culiacan\raw" -Force

# Recolectar un dÃ­a especÃ­fico (ejemplo: 2024-09-01)
snscrape --jsonl twitter-search "Culiacan OR CuliacÃ¡n OR `"Culiacan Sinaloa`" lang:es since:2024-09-01 until:2024-09-02 -filter:retweets" > data_tweets_culiacan\raw\tweets_2024-09-01.jsonl

# Ver cuÃ¡ntos tweets se obtuvieron
Get-Content data_tweets_culiacan\raw\tweets_2024-09-01.jsonl | Measure-Object -Line

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ ESTRUCTURA DE ARCHIVOS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

DespuÃ©s de la recolecciÃ³n, tendrÃ¡s:

Homicidios_cln_v2/
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ scrapping/
â”‚       â”œâ”€â”€ config_tweets.py                    â† Tu configuraciÃ³n personalizada
â”‚       â”œâ”€â”€ recolectar_tweets_culiacan.ps1      â† Script de recolecciÃ³n generado
â”‚       â”œâ”€â”€ ejemplo_uso_completo.py             â† Para procesar despuÃ©s
â”‚       â””â”€â”€ ...
â”‚
â””â”€â”€ data_tweets_culiacan/                        â† Se crea automÃ¡ticamente
    â”œâ”€â”€ raw/                                     â† Tweets crudos (395 archivos)
    â”‚   â”œâ”€â”€ tweets_2024-09-01.jsonl
    â”‚   â”œâ”€â”€ tweets_2024-09-02.jsonl
    â”‚   â””â”€â”€ ... (393 archivos mÃ¡s)
    â”‚
    â”œâ”€â”€ resultados/                              â† Datos procesados (despuÃ©s)
    â”‚   â”œâ”€â”€ tweets_clasificados_XXXXXX.csv
    â”‚   â”œâ”€â”€ resumen_diario_XXXXXX.csv
    â”‚   â””â”€â”€ analisis_anual_XXXXXX.json
    â”‚
    â””â”€â”€ visualizaciones/                         â† GrÃ¡ficos (despuÃ©s)
        â”œâ”€â”€ serie_temporal_emociones.png
        â”œâ”€â”€ calendario_emociones.png
        â””â”€â”€ ... (5 grÃ¡ficos mÃ¡s)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âš ï¸  IMPORTANTE:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. La recolecciÃ³n tomarÃ¡ 6-7 horas. Es NORMAL.

2. Puedes pausar (Ctrl+C) y reanudar ejecutando el script de nuevo.
   Los archivos ya descargados no se volverÃ¡n a descargar.

3. Twitter/X puede limitar el scraping si haces demasiados requests muy rÃ¡pido.
   El script ya incluye pausas razonables.

4. Si algunos dÃ­as no tienen tweets, es normal. No todos los dÃ­as hay menciones
   de CuliacÃ¡n en Twitter.

5. NO ejecutes mÃºltiples veces el mismo dÃ­a sin verificar. Esto puede causar
   duplicados o sobrescribir datos.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ”§ TROUBLESHOOTING:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âŒ Error: "snscrape: command not found"
   â†’ Instalar: pip install snscrape
   
   Si persiste:
   â†’ pip install git+https://github.com/JustAnotherArchivist/snscrape.git

âŒ Error: "No se puede ejecutar scripts en este sistema"
   â†’ Ejecuta en PowerShell como Administrador:
     Set-ExecutionPolicy RemoteSigned -Scope CurrentUser

âŒ Error: Archivos vacÃ­os o muy pocos tweets
   â†’ Verifica las palabras clave
   â†’ Prueba con un dÃ­a reciente primero (ej: 2025-09-30)
   â†’ Twitter/X puede tener limitaciones en el scraping

âŒ Error: "Access denied" o rate limit
   â†’ Espera 15-30 minutos
   â†’ AÃ±ade pausas mÃ¡s largas entre requests

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ’¡ TIPS PRO:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ“ Ejecuta la recolecciÃ³n durante la noche (deja la PC encendida)

âœ“ Usa un dÃ­a reciente para probar primero:
  snscrape --jsonl twitter-search "Culiacan OR CuliacÃ¡n lang:es since:2025-09-30 until:2025-10-01 -filter:retweets" > test.jsonl

âœ“ Monitorea el tamaÃ±o de archivos:
  Get-ChildItem data_tweets_culiacan\raw\*.jsonl | Measure-Object -Property Length -Sum

âœ“ Cuenta tweets totales despuÃ©s:
  Get-Content data_tweets_culiacan\raw\*.jsonl | Measure-Object -Line

âœ“ Haz backup de data_tweets_culiacan/raw/ cuando termines
  (son datos valiosos y la recolecciÃ³n toma mucho tiempo)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ PRÃ“XIMOS PASOS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

DespuÃ©s de completar la recolecciÃ³n:

1. Instalar dependencias de procesamiento:
   pip install -r utils\scrapping\requirements_tweets.txt

2. Procesar y clasificar:
   python utils\scrapping\ejemplo_uso_completo.py
   â†’ OpciÃ³n 3: Procesar tweets

3. Generar visualizaciones:
   â†’ OpciÃ³n 4: Generar visualizaciones

4. Integrar con tu modelo de homicidios:
   â†’ Ver utils\scrapping\README_TWEETS.md (secciÃ³n "IntegraciÃ³n")

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Â¡LISTO PARA EMPEZAR! ğŸš€

Ejecuta: .\utils\scrapping\recolectar_tweets_culiacan.ps1

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
