"""
Script de demostraci√≥n del sistema de an√°lisis de emociones en tweets
Ejecuta el pipeline completo con datos sint√©ticos
"""

import sys
import os
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

print("=" * 80)
print("DEMOSTRACI√ìN DEL SISTEMA DE AN√ÅLISIS DE EMOCIONES EN TWEETS")
print("=" * 80)
print()

# Configuraci√≥n
DIAS_PRUEBA = 30  # Generar 30 d√≠as de datos de prueba
TWEETS_POR_DIA = 50  # 50 tweets por d√≠a
CARPETA_SALIDA = "../../data_tweets_culiacan"

print(f"Configuraci√≥n:")
print(f"  - D√≠as de prueba: {DIAS_PRUEBA}")
print(f"  - Tweets por d√≠a: {TWEETS_POR_DIA}")
print(f"  - Total tweets: {DIAS_PRUEBA * TWEETS_POR_DIA}")
print()

# Paso 1: Generar datos sint√©ticos
print("=" * 80)
print("PASO 1: GENERANDO DATOS SINT√âTICOS")
print("=" * 80)

# Templates de tweets por emoci√≥n
templates_por_emocion = {
    'alegria': [
        "¬°Qu√© bonito d√≠a en Culiac√°n! El sol brillando hermoso üåû",
        "Feliz de estar en Culiac√°n, la ciudad m√°s bella de Sinaloa ‚ù§Ô∏è",
        "Excelente ambiente en Culiac√°n hoy, todo tranquilo üòä",
        "Me encanta vivir en Culiac√°n, gran ciudad üèôÔ∏è‚ú®",
        "Qu√© orgullo ser de Culiac√°n Sinaloa üí™‚ù§Ô∏è",
    ],
    'tristeza': [
        "Otro d√≠a dif√≠cil en Culiac√°n, extra√±o la paz üò¢",
        "Me duele ver lo que pasa en Culiac√°n √∫ltimamente üíî",
        "Qu√© tristeza la situaci√≥n de Culiac√°n üòû",
        "Culiac√°n ya no es como antes, qu√© nostalgia",
        "D√≠as oscuros para Culiac√°n Sinaloa üñ§",
    ],
    'ira': [
        "¬°Ya basta! Culiac√°n merece mejor üò°",
        "Estoy harto de la inseguridad en Culiac√°n!",
        "Qu√© coraje la situaci√≥n en Culiac√°n Sinaloa üò§",
        "Me da rabia lo que est√°n haciendo con Culiac√°n",
        "No puede ser posible lo que pasa en Culiac√°n, ¬°ya!",
    ],
    'miedo': [
        "Preocupado por la situaci√≥n en Culiac√°n üò∞",
        "Tengo miedo de salir en Culiac√°n √∫ltimamente",
        "¬øAlguien m√°s nervioso por Culiac√°n? üò®",
        "Situaci√≥n tensa en Culiac√°n Sinaloa, cuidado",
        "Me da miedo pensar en el futuro de Culiac√°n üòî",
    ],
    'sorpresa': [
        "¬°No puedo creer lo que vi en Culiac√°n! üò≤",
        "¬øEn serio pas√≥ eso en Culiac√°n? ¬°WOW!",
        "Impresionante lo de Culiac√°n Sinaloa üòÆ",
        "¬°Qu√©! ¬øEso en Culiac√°n? No lo esperaba",
        "Sorprendido por las noticias de Culiac√°n ü§Ø",
    ]
}

# Generar tweets
tweets_generados = []
fecha_inicio = datetime.now() - timedelta(days=DIAS_PRUEBA)

print(f"Generando {TWEETS_POR_DIA} tweets por d√≠a durante {DIAS_PRUEBA} d√≠as...")
print()

for dia in range(DIAS_PRUEBA):
    fecha = fecha_inicio + timedelta(days=dia)
    fecha_str = fecha.strftime("%Y-%m-%d")
    
    # Distribuci√≥n realista de emociones (no uniforme)
    distribucion = {
        'alegria': 0.25,
        'tristeza': 0.20,
        'ira': 0.15,
        'miedo': 0.25,
        'sorpresa': 0.15
    }
    
    for i in range(TWEETS_POR_DIA):
        # Seleccionar emoci√≥n seg√∫n distribuci√≥n
        emocion = np.random.choice(
            list(distribucion.keys()),
            p=list(distribucion.values())
        )
        
        # Seleccionar template aleatorio
        texto = np.random.choice(templates_por_emocion[emocion])
        
        # Agregar variaci√≥n
        variaciones = [
            texto,
            texto + " #Culiac√°n",
            texto + " #Culiac√°nSinaloa",
            f"{texto} üôè",
        ]
        texto_final = np.random.choice(variaciones)
        
        tweets_generados.append({
            'fecha': fecha_str,
            'texto': texto_final,
            'emocion_real': emocion  # Para validaci√≥n
        })
    
    if (dia + 1) % 10 == 0:
        print(f"  ‚úì Generados {(dia + 1) * TWEETS_POR_DIA} tweets ({dia + 1}/{DIAS_PRUEBA} d√≠as)")

df_tweets = pd.DataFrame(tweets_generados)
print(f"\n‚úì Total generados: {len(df_tweets)} tweets")
print(f"  Distribuci√≥n de emociones:")
for emocion, count in df_tweets['emocion_real'].value_counts().items():
    porcentaje = (count / len(df_tweets)) * 100
    print(f"    - {emocion.capitalize()}: {count} ({porcentaje:.1f}%)")
print()

# Paso 2: Cargar el analizador
print("=" * 80)
print("PASO 2: CARGANDO MODELO DE AN√ÅLISIS DE EMOCIONES")
print("=" * 80)

try:
    from tweets_sentiments_test import TweetsEmotionAnalyzer
    
    print("Inicializando TweetsEmotionAnalyzer...")
    analizador = TweetsEmotionAnalyzer()
    print("‚úì Analizador cargado correctamente")
    print()
    
except Exception as e:
    print(f"‚úó Error al cargar el analizador: {e}")
    print()
    print("NOTA: El modelo pysentimiento se descargar√° autom√°ticamente en la primera ejecuci√≥n")
    print("      Esto puede tomar varios minutos dependiendo de tu conexi√≥n")
    print()
    sys.exit(1)

# Paso 3: Clasificar emociones
print("=" * 80)
print("PASO 3: CLASIFICANDO EMOCIONES CON MODELO PYSENTIMIENTO")
print("=" * 80)

print("Aplicando modelo a cada tweet...")
print("(Esto puede tardar unos minutos para el primer an√°lisis)")
print()

try:
    # Clasificar en batches para mostrar progreso
    batch_size = 100
    total_batches = (len(df_tweets) + batch_size - 1) // batch_size
    
    emociones_predichas = []
    scores = []
    
    for i in range(0, len(df_tweets), batch_size):
        batch = df_tweets.iloc[i:i+batch_size]
        batch_num = i // batch_size + 1
        
        for _, row in batch.iterrows():
            resultado = analizador.clasificar_emocion(row['texto'])
            emociones_predichas.append(resultado['emocion'])
            scores.append(resultado['score'])
        
        print(f"  ‚úì Procesado batch {batch_num}/{total_batches} ({len(emociones_predichas)}/{len(df_tweets)} tweets)")
    
    df_tweets['emocion_predicha'] = emociones_predichas
    df_tweets['score'] = scores
    
    print()
    print(f"‚úì Clasificaci√≥n completada: {len(df_tweets)} tweets analizados")
    print()
    
except Exception as e:
    print(f"‚úó Error durante la clasificaci√≥n: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# Paso 4: Validar precisi√≥n
print("=" * 80)
print("PASO 4: VALIDANDO PRECISI√ìN DEL MODELO")
print("=" * 80)

# Calcular accuracy
coincidencias = (df_tweets['emocion_real'] == df_tweets['emocion_predicha']).sum()
accuracy = (coincidencias / len(df_tweets)) * 100

print(f"Precisi√≥n global: {accuracy:.1f}% ({coincidencias}/{len(df_tweets)} correctos)")
print()

# Matriz de confusi√≥n simplificada
print("Comparaci√≥n Emoci√≥n Real vs Predicha:")
print("-" * 60)
for emocion in ['alegria', 'tristeza', 'ira', 'miedo', 'sorpresa']:
    subset = df_tweets[df_tweets['emocion_real'] == emocion]
    if len(subset) > 0:
        correctos = (subset['emocion_predicha'] == emocion).sum()
        precision_emocion = (correctos / len(subset)) * 100
        print(f"  {emocion.capitalize():12} - {correctos:3}/{len(subset):3} correctos ({precision_emocion:5.1f}%)")
print()

# Paso 5: Agregaci√≥n por d√≠a
print("=" * 80)
print("PASO 5: AGREGANDO DATOS POR D√çA")
print("=" * 80)

print("Calculando estad√≠sticas diarias...")

# Preparar DataFrame para agregaci√≥n
df_analisis = df_tweets[['fecha', 'texto', 'emocion_predicha', 'score']].copy()
df_analisis.columns = ['fecha', 'texto', 'emocion', 'score']

# Agregar por d√≠a
df_diario = analizador.agregar_por_dia(df_analisis)

print(f"‚úì Datos agregados: {len(df_diario)} d√≠as")
print()
print("Primeros 5 d√≠as:")
print(df_diario.head().to_string(index=False))
print()
print("√öltimos 5 d√≠as:")
print(df_diario.tail().to_string(index=False))
print()

# Paso 6: Guardar resultados
print("=" * 80)
print("PASO 6: GUARDANDO RESULTADOS")
print("=" * 80)

# Crear carpetas si no existen
os.makedirs(f"{CARPETA_SALIDA}/procesado", exist_ok=True)
os.makedirs(f"{CARPETA_SALIDA}/resultados", exist_ok=True)
os.makedirs(f"{CARPETA_SALIDA}/visualizaciones", exist_ok=True)

# Guardar CSVs
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

archivo_tweets = f"{CARPETA_SALIDA}/procesado/tweets_clasificados_DEMO_{timestamp}.csv"
archivo_diario = f"{CARPETA_SALIDA}/resultados/emociones_diarias_DEMO_{timestamp}.csv"

df_tweets.to_csv(archivo_tweets, index=False, encoding='utf-8-sig')
df_diario.to_csv(archivo_diario, index=False, encoding='utf-8-sig')

print(f"‚úì Tweets clasificados guardados en:")
print(f"  {archivo_tweets}")
print()
print(f"‚úì Resumen diario guardado en:")
print(f"  {archivo_diario}")
print()

# Paso 7: Generar visualizaciones
print("=" * 80)
print("PASO 7: GENERANDO VISUALIZACIONES")
print("=" * 80)

try:
    from visualizador_emociones import VisualizadorEmociones
    
    carpeta_viz = f"{CARPETA_SALIDA}/visualizaciones"
    
    print("Inicializando visualizador...")
    viz = VisualizadorEmociones(carpeta_viz)
    
    visualizaciones = [
        ("Serie Temporal de Porcentajes", lambda: viz.serie_temporal_porcentajes(df_diario)),
        ("Calendario de Emociones", lambda: viz.calendario_emociones(df_diario)),
        ("Distribuci√≥n Anual", lambda: viz.distribucion_anual(df_diario)),
        ("Intensidad por Emoci√≥n", lambda: viz.intensidad_por_emocion(df_diario)),
        ("D√≠as M√°s Intensos", lambda: viz.dias_mas_intensos(df_diario)),
        ("Evoluci√≥n Mensual", lambda: viz.evolucion_mensual(df_diario)),
        ("Dashboard Completo", lambda: viz.dashboard_completo(df_diario)),
    ]
    
    for i, (nombre, func) in enumerate(visualizaciones, 1):
        print(f"  [{i}/7] Generando {nombre}...", end=" ")
        try:
            func()
            print("‚úì")
        except Exception as e:
            print(f"‚úó Error: {e}")
            import traceback
            traceback.print_exc()
    
    print()
    print(f"‚úì Visualizaciones guardadas en: {carpeta_viz}")
    print()
    
except Exception as e:
    print(f"‚úó Error al generar visualizaciones: {e}")
    import traceback
    traceback.print_exc()
    print()

# Resumen final
print("=" * 80)
print("RESUMEN DE LA DEMOSTRACI√ìN")
print("=" * 80)
print()
print(f"‚úì Sistema de an√°lisis de emociones funcionando correctamente")
print()
print(f"DATOS PROCESADOS:")
print(f"  - {len(df_tweets)} tweets clasificados")
print(f"  - {DIAS_PRUEBA} d√≠as analizados")
print(f"  - Precisi√≥n del modelo: {accuracy:.1f}%")
print(f"  - Score promedio: {df_tweets['score'].mean():.3f}")
print()
print(f"DISTRIBUCI√ìN FINAL DE EMOCIONES:")
for emocion in ['alegria', 'tristeza', 'ira', 'miedo', 'sorpresa']:
    # Contar directamente del DataFrame de tweets clasificados
    count = (df_tweets['emocion_predicha'] == emocion).sum()
    pct = (count / len(df_tweets)) * 100
    print(f"  - {emocion.capitalize():12}: {pct:5.1f}%")
print()
print(f"ARCHIVOS GENERADOS:")
print(f"  - Tweets clasificados: {archivo_tweets}")
print(f"  - Resumen diario: {archivo_diario}")
if 'carpeta_viz' in locals():
    print(f"  - Visualizaciones: {carpeta_viz}/")
print()
print("=" * 80)
print("¬°DEMOSTRACI√ìN COMPLETADA CON √âXITO!")
print("=" * 80)
print()
print("NOTA: Estos son datos sint√©ticos de demostraci√≥n.")
print("Para an√°lisis real, necesitas:")
print("  1. API de Twitter/X (recomendado para investigaci√≥n acad√©mica)")
print("  2. Scraping de noticias locales (R√≠odoce, Noroeste)")
print("  3. Otras fuentes de datos sobre Culiac√°n")
print()
print("¬øQuieres que te ayude a configurar alguna de estas opciones?")
print()
