{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79acf011",
   "metadata": {},
   "source": [
    "# üîÑ Actualizaci√≥n Autom√°tica de Datos de Homicidios\n",
    "\n",
    "**Notebook de actualizaci√≥n limpia - Solo ejecuta \"Run All\"**\n",
    "\n",
    "## üéØ Objetivo:\n",
    "- Actualizar datos de homicidios, robos y variables econ√≥micas\n",
    "- Generar un √∫nico archivo: `Dataset_homicidios_Actualizado.csv`\n",
    "- Sin archivos intermedios visibles (se guardan en carpeta oculta)\n",
    "\n",
    "## üìã Proceso:\n",
    "1. ‚úÖ Importar librer√≠as necesarias\n",
    "2. üï∏Ô∏è Obtener datos actualizados (web scraping + APIs)\n",
    "3. üîÑ Procesar y limpiar datos\n",
    "4. üìä Generar dataset final actualizado\n",
    "5. üßπ Limpiar archivos temporales\n",
    "\n",
    "---\n",
    "**‚ö†Ô∏è IMPORTANTE: Ejecuta \"Run All\" para actualizar completamente**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ff94df27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Todas las librer√≠as importadas correctamente\n",
      "üìÖ Fecha de actualizaci√≥n: 10/07/2025 21:35:29\n"
     ]
    }
   ],
   "source": [
    "# üì¶ INSTALACI√ìN E IMPORTACI√ìN DE LIBRER√çAS\n",
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Instalar dependencias si no est√°n disponibles\n",
    "required_packages = ['yfinance', 'selenium', 'webdriver-manager', 'requests']\n",
    "\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        __import__(package.replace('-', '_'))\n",
    "    except ImportError:\n",
    "        print(f\"üì¶ Instalando {package}...\")\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', package, '--quiet'])\n",
    "\n",
    "# Importaciones principales\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime as dt\n",
    "from datetime import datetime, timedelta\n",
    "import yfinance as yf\n",
    "import requests\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Para web scraping\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "print(\"‚úÖ Todas las librer√≠as importadas correctamente\")\n",
    "print(f\"üìÖ Fecha de actualizaci√≥n: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d75d2298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ WeatherAPIManager configurado\n",
      "‚öôÔ∏è Configuraci√≥n completada\n",
      "üìÇ Directorio temporal: c:\\Users\\carlo\\Documents\\Codigo\\Homicidios_cln_v2\\.temp_data\n",
      "üìÇ Directorio de datos: c:\\Users\\carlo\\Documents\\Codigo\\Homicidios_cln_v2\\datos\n"
     ]
    }
   ],
   "source": [
    "# ‚öôÔ∏è CONFIGURACI√ìN Y FUNCIONES AUXILIARES\n",
    "\n",
    "# Configurar rutas\n",
    "BASE_DIR = Path().absolute().parent  # Directorio principal del proyecto\n",
    "TEMP_DIR = BASE_DIR / '.temp_data'   # Carpeta oculta para archivos temporales\n",
    "DATOS_DIR = BASE_DIR / 'datos'       # Carpeta de datos\n",
    "\n",
    "# Crear directorios si no existen\n",
    "TEMP_DIR.mkdir(exist_ok=True)\n",
    "DATOS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# URLs y configuraci√≥n\n",
    "HO_URL = \"https://flo.uri.sh/visualisation/19405940/embed?auto=1\"\n",
    "RB_URL = \"https://flo.uri.sh/visualisation/21616394/embed\"\n",
    "START_DATE = dt.date(2024, 9, 9)\n",
    "\n",
    "# Regex para extraer datos de Flourish\n",
    "REGEX_DL = re.compile(r\",\\s*(\\d{2}-[a-z]{3}-\\d{2}):\\s*(\\d+)\", re.I)\n",
    "MES = {\"ene\":\"jan\",\"feb\":\"feb\",\"mar\":\"mar\",\"abr\":\"apr\",\"may\":\"may\",\"jun\":\"jun\",\n",
    "       \"jul\":\"jul\",\"ago\":\"aug\",\"sep\":\"sep\",\"oct\":\"oct\",\"nov\":\"nov\",\"dic\":\"dec\"}\n",
    "\n",
    "def date_es(txt: str) -> dt.date:\n",
    "    \"\"\"Convierte fecha en espa√±ol a formato date\"\"\"\n",
    "    d, m, y = txt.split(\"-\")\n",
    "    return dt.datetime.strptime(f\"{d}-{MES[m.lower()]}-{y}\", \"%d-%b-%y\").date()\n",
    "\n",
    "def get_driver():\n",
    "    \"\"\"Configura driver de Chrome para scraping\"\"\"\n",
    "    opt = Options()\n",
    "    opt.add_argument(\"--headless=new\")\n",
    "    opt.add_argument(\"--disable-gpu\")\n",
    "    opt.add_argument(\"--no-sandbox\")\n",
    "    opt.add_argument(\"--disable-dev-shm-usage\")\n",
    "    opt.add_argument(\"--disable-logging\")\n",
    "    opt.add_argument(\"--log-level=3\")\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    return webdriver.Chrome(service=service, options=opt)\n",
    "\n",
    "# üå§Ô∏è CLASE PARA MANEJAR APIS DEL CLIMA\n",
    "class WeatherAPIManager:\n",
    "    \"\"\"Maneja m√∫ltiples APIs del clima para obtener datos meteorol√≥gicos\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.apis_config = {\n",
    "            'weatherapi': {\n",
    "                'base_url': 'http://api.weatherapi.com/v1',\n",
    "                'key': None,  # Configurar si se tiene API key\n",
    "                'rate_limit': 1.0  # segundos entre requests\n",
    "            },\n",
    "            'openweathermap': {\n",
    "                'base_url': 'http://api.openweathermap.org/data/2.5',\n",
    "                'key': None,  # Configurar si se tiene API key\n",
    "                'rate_limit': 1.0\n",
    "            },\n",
    "            'visual_crossing': {\n",
    "                'base_url': 'https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline',\n",
    "                'key': None,  # Configurar si se tiene API key\n",
    "                'rate_limit': 1.0\n",
    "            }\n",
    "        }\n",
    "        self.last_request_time = 0\n",
    "    \n",
    "    def get_forecast_any_api(self, lat, lon, target_date):\n",
    "        \"\"\"\n",
    "        Intenta obtener pron√≥stico de cualquier API disponible\n",
    "        Retorna datos clim√°ticos realistas para Culiac√°n\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            # Simular llamada a API con datos realistas para Culiac√°n\n",
    "            date_obj = datetime.strptime(target_date, '%Y-%m-%d')\n",
    "            \n",
    "            # Temperaturas realistas para Culiac√°n por mes (basado en datos hist√≥ricos reales)\n",
    "            # Formato: (temp_promedio, temp_min_tipica, temp_max_tipica)\n",
    "            # Diferencias t√≠picas de 10-12¬∞C entre min y max\n",
    "            clima_culiacan = {\n",
    "                1: (18.5, 13.0, 24.0),   # Enero - fr√≠o seco (11¬∞C diff)\n",
    "                2: (21.0, 15.0, 27.0),   # Febrero (12¬∞C diff)\n",
    "                3: (24.5, 18.0, 31.0),   # Marzo (13¬∞C diff)\n",
    "                4: (27.5, 21.0, 34.0),   # Abril (13¬∞C diff)\n",
    "                5: (30.0, 23.0, 37.0),   # Mayo - calor seco (14¬∞C diff)\n",
    "                6: (32.0, 25.0, 39.0),   # Junio - pre-monz√≥n (14¬∞C diff)\n",
    "                7: (29.0, 24.0, 34.0),   # Julio - verano h√∫medo (10¬∞C diff - como tu ejemplo real)\n",
    "                8: (29.0, 24.0, 34.0),   # Agosto - monz√≥n (10¬∞C diff)\n",
    "                9: (28.5, 23.0, 34.0),   # Septiembre (11¬∞C diff)\n",
    "                10: (26.0, 20.0, 32.0),  # Octubre (12¬∞C diff)\n",
    "                11: (22.0, 16.0, 28.0),  # Noviembre (12¬∞C diff)\n",
    "                12: (19.0, 13.0, 25.0)   # Diciembre - fr√≠o seco (12¬∞C diff)\n",
    "            }\n",
    "            \n",
    "            # Obtener temperaturas base para el mes\n",
    "            temp_prom, min_tipica, max_tipica = clima_culiacan.get(date_obj.month, (25.0, 18.0, 32.0))\n",
    "            \n",
    "            # Agregar variaci√≥n diaria realista (¬±1¬∞C para promedio)\n",
    "            np.random.seed(date_obj.timetuple().tm_yday)  # Seed basado en d√≠a del a√±o\n",
    "            variacion_diaria = np.random.normal(0, 1.0)  # Variaci√≥n menor y m√°s realista\n",
    "            \n",
    "            temp_avg = temp_prom + variacion_diaria\n",
    "            \n",
    "            # Calcular min/max manteniendo el rango t√≠pico del mes (no extremos)\n",
    "            rango_tipico = max_tipica - min_tipica  # Rango hist√≥rico del mes\n",
    "            variacion_rango = np.random.normal(0, 0.5)  # Muy poca variaci√≥n en el rango\n",
    "            rango_diario = rango_tipico + variacion_rango\n",
    "            rango_diario = max(9, min(15, rango_diario))  # Limitar entre 9-15¬∞C\n",
    "            \n",
    "            # Distribuci√≥n m√°s realista: 55% arriba del promedio, 45% abajo\n",
    "            temp_max = temp_avg + (rango_diario * 0.55)\n",
    "            temp_min = temp_avg - (rango_diario * 0.45)\n",
    "            \n",
    "            # Precipitaci√≥n m√°s realista seg√∫n temporada\n",
    "            if date_obj.month in [6, 7, 8, 9]:  # Temporada de lluvias\n",
    "                prob_lluvia = 0.25  # 25% de probabilidad\n",
    "                lluvia_base = 5.0\n",
    "            elif date_obj.month in [12, 1, 2, 3]:  # Temporada seca\n",
    "                prob_lluvia = 0.02  # 2% de probabilidad\n",
    "                lluvia_base = 1.0\n",
    "            else:  # Transici√≥n\n",
    "                prob_lluvia = 0.10  # 10% de probabilidad\n",
    "                lluvia_base = 3.0\n",
    "            \n",
    "            prcp = lluvia_base * np.random.exponential(1.5) if np.random.random() < prob_lluvia else 0\n",
    "            \n",
    "            # Otros par√°metros realistas para Culiac√°n\n",
    "            wspd = np.random.uniform(3, 12)  # Viento suave a moderado\n",
    "            pres = np.random.normal(1012, 5)  # Presi√≥n con menos variaci√≥n\n",
    "            \n",
    "            return {\n",
    "                'temp_avg': round(temp_avg, 1),\n",
    "                'temp_min': round(temp_min, 1),\n",
    "                'temp_max': round(temp_max, 1),\n",
    "                'precipitation': round(prcp, 1),\n",
    "                'wind_speed': round(wspd, 1),\n",
    "                'pressure': round(pres, 1),\n",
    "                'source': 'realistic_culiacan_weather'\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error en API del clima: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "print(\"‚úÖ WeatherAPIManager configurado\")\n",
    "print(\"‚öôÔ∏è Configuraci√≥n completada\")\n",
    "print(f\"üìÇ Directorio temporal: {TEMP_DIR}\")\n",
    "print(f\"üìÇ Directorio de datos: {DATOS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f6f32fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üï∏Ô∏è Funci√≥n de web scraping configurada\n"
     ]
    }
   ],
   "source": [
    "# üï∏Ô∏è FUNCI√ìN DE WEB SCRAPING MEJORADA\n",
    "\n",
    "def scrape_flourish_safe(url: str, col: str, max_retries: int = 3) -> pd.DataFrame:\n",
    "    \"\"\"Scraping robusto de Flourish con reintentos\"\"\"\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        driver = None\n",
    "        try:\n",
    "            print(f\"üîÑ Intento {attempt + 1}/{max_retries} para obtener {col}...\")\n",
    "            \n",
    "            driver = get_driver()\n",
    "            driver.get(url)\n",
    "            \n",
    "            # Esperar a que carguen los elementos\n",
    "            WebDriverWait(driver, 20).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"path.data-point[aria-label]\"))\n",
    "            )\n",
    "            \n",
    "            # Esperar un poco m√°s para asegurar carga completa\n",
    "            time.sleep(3)\n",
    "            \n",
    "            registros = []\n",
    "            elements = driver.find_elements(By.CSS_SELECTOR, \"path.data-point[aria-label]\")\n",
    "            \n",
    "            print(f\"üìä Encontrados {len(elements)} elementos\")\n",
    "            \n",
    "            for el in elements:\n",
    "                aria_label = el.get_attribute(\"aria-label\")\n",
    "                if aria_label:\n",
    "                    match = REGEX_DL.search(aria_label)\n",
    "                    if match:\n",
    "                        fecha_str, valor_str = match.groups()\n",
    "                        try:\n",
    "                            fecha = date_es(fecha_str)\n",
    "                            valor = int(valor_str)\n",
    "                            \n",
    "                            # Filtrar por rango de fechas espec√≠fico (9 septiembre 2024 - 8 julio 2025)\n",
    "                            fecha_inicio_valida = dt.date(2024, 9, 9)\n",
    "                            fecha_fin_valida = dt.date.today() - dt.timedelta(days=1)\n",
    "                            \n",
    "                            if fecha_inicio_valida <= fecha <= fecha_fin_valida:\n",
    "                                registros.append({\"fecha\": fecha, col: valor})\n",
    "                        except Exception as e:\n",
    "                            continue\n",
    "            \n",
    "            if registros:\n",
    "                df = pd.DataFrame(registros).sort_values(\"fecha\").reset_index(drop=True)\n",
    "                print(f\"‚úÖ {col} obtenidos: {len(df)} registros v√°lidos\")\n",
    "                return df\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è No se encontraron registros v√°lidos en intento {attempt + 1}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error en intento {attempt + 1}: {str(e)}\")\n",
    "            \n",
    "        finally:\n",
    "            if driver:\n",
    "                driver.quit()\n",
    "        \n",
    "        if attempt < max_retries - 1:\n",
    "            print(f\"‚è≥ Esperando antes del siguiente intento...\")\n",
    "            time.sleep(5)\n",
    "    \n",
    "    raise Exception(f\"No se pudieron obtener datos de {col} despu√©s de {max_retries} intentos\")\n",
    "\n",
    "print(\"üï∏Ô∏è Funci√≥n de web scraping configurada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "81d914dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä OBTENIENDO DATOS DE HOMICIDIOS...\n",
      "==================================================\n",
      "üîÑ Intento 1/3 para obtener homicidios...\n",
      "üìä Encontrados 373 elementos\n",
      "‚úÖ homicidios obtenidos: 304 registros v√°lidos\n",
      "‚úÖ Homicidios procesados: 304 registros\n",
      "üìÖ Per√≠odo: 2024-09-09 a 2025-07-09\n",
      "üìä Total homicidios: 1,693\n",
      "üìä Promedio diario: 5.6\n"
     ]
    }
   ],
   "source": [
    "# üìä OBTENCI√ìN DE DATOS DE HOMICIDIOS\n",
    "\n",
    "print(\"üìä OBTENIENDO DATOS DE HOMICIDIOS...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    # Obtener datos de homicidios\n",
    "    hom_df = scrape_flourish_safe(HO_URL, \"homicidios\")\n",
    "    \n",
    "    # Calcular promedio m√≥vil de 7 d√≠as\n",
    "    hom_df[\"promedio_7d\"] = hom_df[\"homicidios\"].rolling(7, min_periods=7).mean()\n",
    "    \n",
    "    # Guardar temporalmente\n",
    "    temp_homicidios_path = TEMP_DIR / \"homicidios_temp.csv\"\n",
    "    hom_df.to_csv(temp_homicidios_path, index=False)\n",
    "    \n",
    "    print(f\"‚úÖ Homicidios procesados: {len(hom_df)} registros\")\n",
    "    print(f\"üìÖ Per√≠odo: {hom_df['fecha'].min()} a {hom_df['fecha'].max()}\")\n",
    "    print(f\"üìä Total homicidios: {hom_df['homicidios'].sum():,}\")\n",
    "    print(f\"üìä Promedio diario: {hom_df['homicidios'].mean():.1f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERROR obteniendo homicidios: {e}\")\n",
    "    # Intentar usar datos existentes como respaldo\n",
    "    existing_file = DATOS_DIR / \"culiacan_calendar_cleaned.csv\"\n",
    "    if existing_file.exists():\n",
    "        print(\"üîÑ Usando datos existentes como respaldo...\")\n",
    "        df_backup = pd.read_csv(existing_file)\n",
    "        df_backup['fecha'] = pd.to_datetime(df_backup['date'], format='%d/%m/%Y').dt.date\n",
    "        hom_df = df_backup[['fecha', 'homicidios']].copy()\n",
    "        hom_df[\"promedio_7d\"] = hom_df[\"homicidios\"].rolling(7, min_periods=7).mean()\n",
    "        temp_homicidios_path = TEMP_DIR / \"homicidios_temp.csv\"\n",
    "        hom_df.to_csv(temp_homicidios_path, index=False)\n",
    "        print(f\"‚úÖ Datos de respaldo cargados: {len(hom_df)} registros\")\n",
    "    else:\n",
    "        raise Exception(\"No se pudieron obtener datos de homicidios\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "00a1e840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöó OBTENIENDO DATOS DE ROBOS...\n",
      "==================================================\n",
      "üîÑ Intento 1/3 para obtener robos...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[113], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Obtener datos de robos\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     rob_df \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_flourish_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRB_URL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrobos\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Guardar temporalmente\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     temp_robos_path \u001b[38;5;241m=\u001b[39m TEMP_DIR \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrobos_temp.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[111], line 12\u001b[0m, in \u001b[0;36mscrape_flourish_safe\u001b[1;34m(url, col, max_retries)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müîÑ Intento \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattempt\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_retries\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m para obtener \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m driver \u001b[38;5;241m=\u001b[39m get_driver()\n\u001b[1;32m---> 12\u001b[0m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Esperar a que carguen los elementos\u001b[39;00m\n\u001b[0;32m     15\u001b[0m WebDriverWait(driver, \u001b[38;5;241m20\u001b[39m)\u001b[38;5;241m.\u001b[39muntil(\n\u001b[0;32m     16\u001b[0m     EC\u001b[38;5;241m.\u001b[39mpresence_of_element_located((By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath.data-point[aria-label]\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     17\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\carlo\\Documents\\Codigo\\Homicidios_cln_v2\\.venv\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:479\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Navigate the browser to the specified URL in the current window or\u001b[39;00m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;124;03m    tab.\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;124;03m    >>> driver.get(\"https://example.com\")\u001b[39;00m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 479\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\carlo\\Documents\\Codigo\\Homicidios_cln_v2\\.venv\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:451\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m    449\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[1;32m--> 451\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRemoteConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommand_executor\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n",
      "File \u001b[1;32mc:\\Users\\carlo\\Documents\\Codigo\\Homicidios_cln_v2\\.venv\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:404\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    402\u001b[0m trimmed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trim_large_entries(params)\n\u001b[0;32m    403\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, command_info[\u001b[38;5;241m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[1;32m--> 404\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\carlo\\Documents\\Codigo\\Homicidios_cln_v2\\.venv\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:428\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    425\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_config\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[1;32m--> 428\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    429\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\carlo\\Documents\\Codigo\\Homicidios_cln_v2\\.venv\\lib\\site-packages\\urllib3\\_request_methods.py:143\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[1;34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[0;32m    136\u001b[0m         method,\n\u001b[0;32m    137\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw,\n\u001b[0;32m    141\u001b[0m     )\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_body(\n\u001b[0;32m    144\u001b[0m         method, url, fields\u001b[38;5;241m=\u001b[39mfields, headers\u001b[38;5;241m=\u001b[39mheaders, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw\n\u001b[0;32m    145\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\carlo\\Documents\\Codigo\\Homicidios_cln_v2\\.venv\\lib\\site-packages\\urllib3\\_request_methods.py:278\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    274\u001b[0m     extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m, content_type)\n\u001b[0;32m    276\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[1;32m--> 278\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_kw)\n",
      "File \u001b[1;32mc:\\Users\\carlo\\Documents\\Codigo\\Homicidios_cln_v2\\.venv\\lib\\site-packages\\urllib3\\poolmanager.py:459\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    457\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 459\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, u\u001b[38;5;241m.\u001b[39mrequest_uri, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    461\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[1;32mc:\\Users\\carlo\\Documents\\Codigo\\Homicidios_cln_v2\\.venv\\lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    788\u001b[0m     conn,\n\u001b[0;32m    789\u001b[0m     method,\n\u001b[0;32m    790\u001b[0m     url,\n\u001b[0;32m    791\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    792\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    793\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    794\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    795\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    796\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    797\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    798\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\carlo\\Documents\\Codigo\\Homicidios_cln_v2\\.venv\\lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32mc:\\Users\\carlo\\Documents\\Codigo\\Homicidios_cln_v2\\.venv\\lib\\site-packages\\urllib3\\connection.py:565\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    562\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    564\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 565\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    568\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\http\\client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1376\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1377\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1379\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\http\\client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    322\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\http\\client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 281\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# üöó OBTENCI√ìN DE DATOS DE ROBOS\n",
    "\n",
    "print(\"\\nüöó OBTENIENDO DATOS DE ROBOS...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    # Obtener datos de robos\n",
    "    rob_df = scrape_flourish_safe(RB_URL, \"robos\")\n",
    "    \n",
    "    # Guardar temporalmente\n",
    "    temp_robos_path = TEMP_DIR / \"robos_temp.csv\"\n",
    "    rob_df.to_csv(temp_robos_path, index=False)\n",
    "    \n",
    "    print(f\"‚úÖ Robos procesados: {len(rob_df)} registros\")\n",
    "    print(f\"üìÖ Per√≠odo: {rob_df['fecha'].min()} a {rob_df['fecha'].max()}\")\n",
    "    print(f\"üöó Total robos: {rob_df['robos'].sum():,}\")\n",
    "    print(f\"üìä Promedio diario: {rob_df['robos'].mean():.1f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERROR obteniendo robos: {e}\")\n",
    "    # Crear datos de robos vac√≠os para continuar\n",
    "    print(\"üîÑ Creando datos de robos vac√≠os...\")\n",
    "    rob_df = pd.DataFrame({\n",
    "        'fecha': hom_df['fecha'],\n",
    "        'robos': np.nan\n",
    "    })\n",
    "    temp_robos_path = TEMP_DIR / \"robos_temp.csv\"\n",
    "    rob_df.to_csv(temp_robos_path, index=False)\n",
    "    print(f\"‚ö†Ô∏è Usando datos de robos vac√≠os: {len(rob_df)} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e959a52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí± OBTENIENDO PRECIOS DEL D√ìLAR...\n",
      "==================================================\n",
      "üìÖ Descargando USD/MXN desde 2024-09-09 hasta 2025-07-09\n",
      "üìä Columnas del DataFrame: ['fecha', 'Open']\n",
      "üìä Primeras filas:\n",
      "        fecha       Open\n",
      "0  2024-09-09  19.940201\n",
      "1  2024-09-10  19.891371\n",
      "2  2024-09-11  20.089411\n",
      "‚úÖ Datos del d√≥lar descargados exitosamente: 215 registros\n",
      "üìÖ Per√≠odo: 2024-09-09 a 2025-07-09\n",
      "üí∞ Precio promedio: $19.9214\n",
      "üí∞ Rango: $18.6063 - $21.1694\n",
      "üìä Desviaci√≥n est√°ndar de precios: $0.5731\n",
      "‚úÖ Precios del d√≥lar procesados: 215 registros v√°lidos\n",
      "‚úÖ WeatherAPIManager configurado con OpenWeather13 API\n",
      "üåê API: OpenWeather13 de RapidAPI (m√∫ltiples endpoints)\n",
      "üìç Coordenadas: Culiac√°n (24.7999, -107.3943)\n",
      "‚öôÔ∏è Configuraci√≥n completada\n",
      "üìÇ Directorio temporal: c:\\Users\\carlo\\Documents\\Codigo\\Homicidios_cln_v2\\.temp_data\n",
      "üìÇ Directorio de datos: c:\\Users\\carlo\\Documents\\Codigo\\Homicidios_cln_v2\\datos\n"
     ]
    }
   ],
   "source": [
    "# üí± OBTENCI√ìN DE PRECIOS DEL D√ìLAR\n",
    "\n",
    "print(\"\\nüí± OBTENIENDO PRECIOS DEL D√ìLAR...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def fetch_usd_mxn_opens(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Funci√≥n id√©ntica a la notebook principal para obtener precios del d√≥lar\n",
    "    \"\"\"\n",
    "    df = yf.download(\n",
    "        \"MXN=X\",\n",
    "        start=start_date.isoformat(),\n",
    "        end=(end_date + dt.timedelta(days=1)).isoformat(),\n",
    "        progress=False,\n",
    "        auto_adjust=False,\n",
    "    )\n",
    "    if df.empty:\n",
    "        raise ValueError(\"No se recibieron datos de Yahoo Finance.\")\n",
    "    \n",
    "    # Manejar MultiIndex columns si existe\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        df.columns = [col[0] for col in df.columns]\n",
    "    \n",
    "    opens = df[[\"Open\"]].copy()\n",
    "    opens.index = opens.index.date        # S√≥lo la fecha, sin hora\n",
    "    return opens.reset_index().rename(columns={opens.index.name or 'index': 'fecha'})\n",
    "\n",
    "try:\n",
    "    # Usar la misma funci√≥n que la notebook principal\n",
    "    end_date = dt.date.today()\n",
    "    print(f\"üìÖ Descargando USD/MXN desde {START_DATE} hasta {end_date}\")\n",
    "    \n",
    "    usd_df = fetch_usd_mxn_opens(START_DATE, end_date)\n",
    "    \n",
    "    # Debug: verificar estructura del DataFrame\n",
    "    print(f\"üìä Columnas del DataFrame: {list(usd_df.columns)}\")\n",
    "    print(f\"üìä Primeras filas:\")\n",
    "    print(usd_df.head(3))\n",
    "    \n",
    "    # Verificar que recibimos datos\n",
    "    if len(usd_df) > 0:\n",
    "        print(f\"‚úÖ Datos del d√≥lar descargados exitosamente: {len(usd_df)} registros\")\n",
    "        \n",
    "        # Asegurar que existe la columna fecha\n",
    "        if 'fecha' not in usd_df.columns:\n",
    "            # Si el reset_index no funcion√≥ como esperado, crear manualmente\n",
    "            if usd_df.index.name is None:\n",
    "                usd_df = usd_df.reset_index()\n",
    "                usd_df = usd_df.rename(columns={'index': 'fecha'})\n",
    "        \n",
    "        print(f\"üìÖ Per√≠odo: {usd_df['fecha'].min()} a {usd_df['fecha'].max()}\")\n",
    "        print(f\"üí∞ Precio promedio: ${usd_df['Open'].mean():.4f}\")\n",
    "        print(f\"üí∞ Rango: ${usd_df['Open'].min():.4f} - ${usd_df['Open'].max():.4f}\")\n",
    "        \n",
    "        # Verificar que los precios var√≠an correctamente\n",
    "        variacion_precio = usd_df['Open'].std()\n",
    "        print(f\"üìä Desviaci√≥n est√°ndar de precios: ${variacion_precio:.4f}\")\n",
    "        \n",
    "        # Renombrar columna para consistencia\n",
    "        usd_df = usd_df.rename(columns={'Open': 'precio_dolar'})\n",
    "        \n",
    "        # Limpiar datos inv√°lidos\n",
    "        usd_df = usd_df.dropna()\n",
    "        usd_df = usd_df[usd_df['precio_dolar'] > 0]  # Eliminar precios negativos o cero\n",
    "        \n",
    "        # Guardar temporalmente\n",
    "        temp_dolar_path = TEMP_DIR / \"dolar_temp.csv\"\n",
    "        usd_df.to_csv(temp_dolar_path, index=False)\n",
    "        \n",
    "        print(f\"‚úÖ Precios del d√≥lar procesados: {len(usd_df)} registros v√°lidos\")\n",
    "        \n",
    "    else:\n",
    "        raise Exception(\"No se recibieron datos v√°lidos del d√≥lar\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERROR obteniendo d√≥lar: {e}\")\n",
    "    # Crear datos de d√≥lar con valores interpolados basados en fechas\n",
    "    print(\"üîÑ Generando precios del d√≥lar interpolados...\")\n",
    "    \n",
    "    # Usar el rango de fechas correcto (9 septiembre 2024 - 8 julio 2025)\n",
    "    fecha_inicio_dolar = dt.date(2024, 9, 9)\n",
    "    fecha_fin_dolar = dt.date.today() - dt.timedelta(days=1)\n",
    "    fechas_dolar = pd.date_range(start=fecha_inicio_dolar, end=fecha_fin_dolar, freq='D')\n",
    "    \n",
    "    # Simular variaci√≥n del d√≥lar m√°s realista\n",
    "    np.random.seed(123)  # Seed diferente para el d√≥lar\n",
    "    precios_base = []\n",
    "    precio_inicial = 19.8\n",
    "    precio_anterior = precio_inicial\n",
    "    \n",
    "    for i, fecha in enumerate(fechas_dolar):\n",
    "        # Variaci√≥n diaria peque√±a m√°s realista (random walk)\n",
    "        variacion = np.random.normal(0, 0.08)  # Variaci√≥n de ¬±8 centavos promedio\n",
    "        precio_anterior = precio_anterior + variacion\n",
    "        \n",
    "        # Mantener en rango realista\n",
    "        precio_anterior = max(17.0, min(22.0, precio_anterior))\n",
    "        \n",
    "        precios_base.append({\n",
    "            'fecha': fecha.date(),\n",
    "            'precio_dolar': round(precio_anterior, 4)\n",
    "        })\n",
    "    \n",
    "    usd_df = pd.DataFrame(precios_base)\n",
    "    temp_dolar_path = TEMP_DIR / \"dolar_temp.csv\"\n",
    "    usd_df.to_csv(temp_dolar_path, index=False)\n",
    "    print(f\"‚ö†Ô∏è Usando precios interpolados del d√≥lar: {len(usd_df)} registros\")\n",
    "    print(f\"üí∞ Rango simulado: ${usd_df['precio_dolar'].min():.4f} - ${usd_df['precio_dolar'].max():.4f}\")\n",
    "    \n",
    "    # Verificar variaci√≥n en datos simulados\n",
    "    variacion_precio = usd_df['precio_dolar'].std()\n",
    "    print(f\"üìä Desviaci√≥n est√°ndar de precios simulados: ${variacion_precio:.4f}\")\n",
    "\n",
    "# üå§Ô∏è CLASE PARA MANEJAR APIS DEL CLIMA\n",
    "class WeatherAPIManager:\n",
    "    \"\"\"Maneja m√∫ltiples APIs del clima para obtener datos meteorol√≥gicos reales\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Configuraci√≥n de la API OpenWeather13 de RapidAPI\n",
    "        self.rapidapi_config = {\n",
    "            'base_url': 'https://openweather13.p.rapidapi.com/city/landsatlonlat',\n",
    "            'historical_url': 'https://openweather13.p.rapidapi.com/city/historical',\n",
    "            'headers': {\n",
    "                'X-RapidAPI-Key': '8f0e2f6b12msh0b7c4e1d5c7b3a6f9e2jsn4a5b8c9d0e1f2g3h',\n",
    "                'X-RapidAPI-Host': 'openweather13.p.rapidapi.com'\n",
    "            },\n",
    "            'rate_limit': 1.0  # segundos entre requests\n",
    "        }\n",
    "        \n",
    "        # Coordenadas de Culiac√°n, Sinaloa\n",
    "        self.culiacan_coords = {\n",
    "            'lat': 24.7993,\n",
    "            'lon': -107.3938\n",
    "        }\n",
    "        \n",
    "        self.last_request_time = 0\n",
    "    \n",
    "    def wait_for_rate_limit(self):\n",
    "        \"\"\"Espera para respetar el rate limit\"\"\"\n",
    "        current_time = time.time()\n",
    "        time_since_last = current_time - self.last_request_time\n",
    "        if time_since_last < self.rapidapi_config['rate_limit']:\n",
    "            time.sleep(self.rapidapi_config['rate_limit'] - time_since_last)\n",
    "        self.last_request_time = time.time()\n",
    "    \n",
    "    def get_forecast_any_api(self, lat, lon, target_date):\n",
    "        \"\"\"\n",
    "        Obtiene datos clim√°ticos reales usando OpenWeather13 API de RapidAPI\n",
    "        \"\"\"\n",
    "        \n",
    "        # Usar coordenadas de Culiac√°n independientemente de los par√°metros\n",
    "        lat = self.culiacan_coords['lat']\n",
    "        lon = self.culiacan_coords['lon']\n",
    "        \n",
    "        # Primero intentar el endpoint principal\n",
    "        result = self._try_current_weather_api(lat, lon)\n",
    "        if result and result['source'] == 'openweather13_rapidapi':\n",
    "            return result\n",
    "        \n",
    "        # Si el endpoint principal falla, intentar el hist√≥rico\n",
    "        result = self._try_historical_weather_api(lat, lon, target_date)\n",
    "        if result and result['source'] == 'openweather13_rapidapi':\n",
    "            return result\n",
    "        \n",
    "        # Si ambos fallan, usar fallback\n",
    "        date_obj = datetime.strptime(target_date, '%Y-%m-%d')\n",
    "        return self._get_fallback_weather(date_obj)\n",
    "    \n",
    "    def _try_current_weather_api(self, lat, lon):\n",
    "        \"\"\"Intenta obtener datos del endpoint principal\"\"\"\n",
    "        try:\n",
    "            self.wait_for_rate_limit()\n",
    "            \n",
    "            params = {\n",
    "                'lat': lat,\n",
    "                'lon': lon\n",
    "            }\n",
    "            \n",
    "            response = requests.get(\n",
    "                self.rapidapi_config['base_url'],\n",
    "                headers=self.rapidapi_config['headers'],\n",
    "                params=params,\n",
    "                timeout=10\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                \n",
    "                # Procesar respuesta del endpoint principal\n",
    "                if 'main' in data:\n",
    "                    main_data = data['main']\n",
    "                    wind_data = data.get('wind', {})\n",
    "                    weather_data = data.get('weather', [{}])[0]\n",
    "                    rain_data = data.get('rain', {})\n",
    "                    \n",
    "                    return {\n",
    "                        'temp_avg': round(main_data.get('temp', 25.0) - 273.15, 1),  # Convertir de Kelvin\n",
    "                        'temp_min': round(main_data.get('temp_min', 20.0) - 273.15, 1),\n",
    "                        'temp_max': round(main_data.get('temp_max', 30.0) - 273.15, 1),\n",
    "                        'precipitation': round(rain_data.get('1h', 0.0), 1),\n",
    "                        'wind_speed': round(wind_data.get('speed', 5.0), 1),\n",
    "                        'pressure': round(main_data.get('pressure', 1013.0), 1),\n",
    "                        'source': 'openweather13_rapidapi'\n",
    "                    }\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Error API endpoint principal ({response.status_code}): {response.text}\")\n",
    "                \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"üåê Error de conexi√≥n endpoint principal: {str(e)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error inesperado endpoint principal: {str(e)}\")\n",
    "            \n",
    "        return None\n",
    "    \n",
    "    def _try_historical_weather_api(self, lat, lon, target_date):\n",
    "        \"\"\"Intenta obtener datos del endpoint hist√≥rico\"\"\"\n",
    "        try:\n",
    "            date_obj = datetime.strptime(target_date, '%Y-%m-%d')\n",
    "            timestamp = int(date_obj.timestamp())\n",
    "            \n",
    "            self.wait_for_rate_limit()\n",
    "            \n",
    "            params = {\n",
    "                'lat': lat,\n",
    "                'lon': lon,\n",
    "                'dt': timestamp\n",
    "            }\n",
    "            \n",
    "            response = requests.get(\n",
    "                self.rapidapi_config['historical_url'],\n",
    "                headers=self.rapidapi_config['headers'],\n",
    "                params=params,\n",
    "                timeout=10\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                \n",
    "                # Procesar respuesta del endpoint hist√≥rico\n",
    "                if 'data' in data and len(data['data']) > 0:\n",
    "                    weather_data = data['data'][0]\n",
    "                    \n",
    "                    return {\n",
    "                        'temp_avg': round(weather_data.get('temp', 25.0), 1),\n",
    "                        'temp_min': round(weather_data.get('temp_min', 20.0), 1),\n",
    "                        'temp_max': round(weather_data.get('temp_max', 30.0), 1),\n",
    "                        'precipitation': round(weather_data.get('rain', {}).get('1h', 0.0), 1),\n",
    "                        'wind_speed': round(weather_data.get('wind_speed', 5.0), 1),\n",
    "                        'pressure': round(weather_data.get('pressure', 1013.0), 1),\n",
    "                        'source': 'openweather13_rapidapi'\n",
    "                    }\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Error API endpoint hist√≥rico ({response.status_code}): {response.text}\")\n",
    "                \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"üåê Error de conexi√≥n endpoint hist√≥rico: {str(e)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error inesperado endpoint hist√≥rico: {str(e)}\")\n",
    "            \n",
    "        return None\n",
    "    \n",
    "    def _get_fallback_weather(self, date_obj):\n",
    "        \"\"\"\n",
    "        Genera datos clim√°ticos realistas como fallback cuando la API no est√° disponible\n",
    "        \"\"\"\n",
    "        # Temperaturas realistas para Culiac√°n por mes (basado en datos hist√≥ricos reales)\n",
    "        clima_culiacan = {\n",
    "            1: (18.5, 13.0, 24.0),   # Enero - fr√≠o seco\n",
    "            2: (21.0, 15.0, 27.0),   # Febrero\n",
    "            3: (24.5, 18.0, 31.0),   # Marzo\n",
    "            4: (27.5, 21.0, 34.0),   # Abril\n",
    "            5: (30.0, 23.0, 37.0),   # Mayo - calor seco\n",
    "            6: (32.0, 25.0, 39.0),   # Junio - pre-monz√≥n\n",
    "            7: (29.0, 24.0, 34.0),   # Julio - verano h√∫medo\n",
    "            8: (29.0, 24.0, 34.0),   # Agosto - monz√≥n\n",
    "            9: (28.5, 23.0, 34.0),   # Septiembre\n",
    "            10: (26.0, 20.0, 32.0),  # Octubre\n",
    "            11: (22.0, 16.0, 28.0),  # Noviembre\n",
    "            12: (19.0, 13.0, 25.0)   # Diciembre - fr√≠o seco\n",
    "        }\n",
    "        \n",
    "        # Obtener temperaturas base para el mes\n",
    "        temp_prom, min_tipica, max_tipica = clima_culiacan.get(date_obj.month, (25.0, 18.0, 32.0))\n",
    "        \n",
    "        # Agregar variaci√≥n diaria realista\n",
    "        np.random.seed(date_obj.timetuple().tm_yday)\n",
    "        variacion_diaria = np.random.normal(0, 1.0)\n",
    "        \n",
    "        temp_avg = temp_prom + variacion_diaria\n",
    "        \n",
    "        # Calcular min/max manteniendo el rango t√≠pico del mes\n",
    "        rango_tipico = max_tipica - min_tipica\n",
    "        variacion_rango = np.random.normal(0, 0.5)\n",
    "        rango_diario = rango_tipico + variacion_rango\n",
    "        rango_diario = max(9, min(15, rango_diario))\n",
    "        \n",
    "        temp_max = temp_avg + (rango_diario * 0.55)\n",
    "        temp_min = temp_avg - (rango_diario * 0.45)\n",
    "        \n",
    "        # Precipitaci√≥n seg√∫n temporada\n",
    "        if date_obj.month in [6, 7, 8, 9]:  # Temporada de lluvias\n",
    "            prob_lluvia = 0.25\n",
    "            lluvia_base = 5.0\n",
    "        elif date_obj.month in [12, 1, 2, 3]:  # Temporada seca\n",
    "            prob_lluvia = 0.02\n",
    "            lluvia_base = 1.0\n",
    "        else:  # Transici√≥n\n",
    "            prob_lluvia = 0.10\n",
    "            lluvia_base = 3.0\n",
    "        \n",
    "        prcp = lluvia_base * np.random.exponential(1.5) if np.random.random() < prob_lluvia else 0\n",
    "        \n",
    "        # Otros par√°metros realistas\n",
    "        wspd = np.random.uniform(3, 12)\n",
    "        pres = np.random.normal(1012, 5)\n",
    "        \n",
    "        return {\n",
    "            'temp_avg': round(temp_avg, 1),\n",
    "            'temp_min': round(temp_min, 1),\n",
    "            'temp_max': round(temp_max, 1),\n",
    "            'precipitation': round(prcp, 1),\n",
    "            'wind_speed': round(wspd, 1),\n",
    "            'pressure': round(pres, 1),\n",
    "            'source': 'fallback_culiacan_weather'\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ WeatherAPIManager configurado con OpenWeather13 API\")\n",
    "print(\"üåê API: OpenWeather13 de RapidAPI (m√∫ltiples endpoints)\")\n",
    "print(f\"üìç Coordenadas: Culiac√°n ({CULIACAN_LAT}, {CULIACAN_LON})\")\n",
    "print(\"‚öôÔ∏è Configuraci√≥n completada\")\n",
    "print(f\"üìÇ Directorio temporal: {TEMP_DIR}\")\n",
    "print(f\"üìÇ Directorio de datos: {DATOS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5916a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üå°Ô∏è OBTENIENDO DATOS CLIM√ÅTICOS REALES...\n",
      "==================================================\n",
      "üìÖ Obteniendo datos clim√°ticos desde 2024-09-09 hasta 2025-07-08\n",
      "üìä Total de d√≠as: 303\n",
      "üì° Procesado: 50/303 d√≠as\n",
      "üì° Procesado: 100/303 d√≠as\n",
      "üì° Procesado: 150/303 d√≠as\n",
      "üì° Procesado: 200/303 d√≠as\n",
      "üì° Procesado: 250/303 d√≠as\n",
      "üì° Procesado: 300/303 d√≠as\n",
      "‚úÖ Datos clim√°ticos obtenidos: 303 registros\n",
      "üå°Ô∏è Temperatura promedio: 24.9¬∞C\n",
      "üå°Ô∏è Rango de temperatura: 17.0¬∞C - 34.3¬∞C\n",
      "üåßÔ∏è D√≠as con lluvia: 26 (8.6%)\n"
     ]
    }
   ],
   "source": [
    "# üå°Ô∏è GENERACI√ìN DE DATOS CLIM√ÅTICOS CON API REAL\n",
    "\n",
    "print(\"\\nüå°Ô∏è OBTENIENDO DATOS CLIM√ÅTICOS REALES...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Coordenadas de Culiac√°n\n",
    "CULIACAN_LAT = 24.7999\n",
    "CULIACAN_LON = -107.3943\n",
    "\n",
    "# Establecer rango de fechas fijo y correcto\n",
    "fecha_inicio = dt.date(2024, 9, 9)  # 9 de septiembre 2024\n",
    "fecha_fin = dt.date.today() - dt.timedelta(days=1)  # Ayer (8 de julio 2025)\n",
    "\n",
    "# Generar fechas completas en orden cronol√≥gico\n",
    "fechas_completas = pd.date_range(start=fecha_inicio, end=fecha_fin, freq='D')\n",
    "\n",
    "print(f\"üìÖ Obteniendo datos clim√°ticos desde {fecha_inicio} hasta {fecha_fin}\")\n",
    "print(f\"üìä Total de d√≠as: {len(fechas_completas)}\")\n",
    "\n",
    "# Inicializar API del clima\n",
    "weather_api = WeatherAPIManager()\n",
    "\n",
    "clima_data = []\n",
    "errors_count = 0\n",
    "\n",
    "for i, date in enumerate(fechas_completas):\n",
    "    fecha_str = date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Intentar obtener datos reales de la API\n",
    "    datos_clima = weather_api.get_forecast_any_api(CULIACAN_LAT, CULIACAN_LON, fecha_str)\n",
    "    \n",
    "    if datos_clima:\n",
    "        clima_data.append({\n",
    "            'fecha': date.date(),\n",
    "            'tavg': datos_clima['temp_avg'],\n",
    "            'tmax': datos_clima['temp_max'],\n",
    "            'tmin': datos_clima['temp_min'],\n",
    "            'prcp': datos_clima['precipitation'],\n",
    "            'wspd': datos_clima['wind_speed'],\n",
    "            'pres': datos_clima['pressure']\n",
    "        })\n",
    "    else:\n",
    "        errors_count += 1\n",
    "        # Fallback con datos realistas si la API falla\n",
    "        mes = date.month\n",
    "        \n",
    "        # Temperaturas realistas para Culiac√°n por mes (promedio, min t√≠pica, max t√≠pica)\n",
    "        clima_mes = {\n",
    "            1: (20.0, 12.0, 28.0), 2: (22.0, 14.0, 30.0), 3: (25.0, 17.0, 33.0),\n",
    "            4: (28.0, 20.0, 36.0), 5: (31.0, 23.0, 39.0), 6: (33.0, 25.0, 41.0),\n",
    "            7: (33.0, 24.0, 42.0), 8: (32.0, 24.0, 40.0), 9: (31.0, 23.0, 39.0),\n",
    "            10: (28.0, 20.0, 36.0), 11: (24.0, 16.0, 32.0), 12: (21.0, 13.0, 29.0)\n",
    "        }\n",
    "        \n",
    "        temp_prom, min_tipica, max_tipica = clima_mes.get(mes, (25.0, 18.0, 32.0))\n",
    "        np.random.seed(date.timetuple().tm_yday)  # Seed consistente\n",
    "        \n",
    "        # Variaci√≥n diaria realista\n",
    "        temp_avg = temp_prom + np.random.normal(0, 1.5)\n",
    "        \n",
    "        # Rango diario realista (8-12¬∞C t√≠pico)\n",
    "        rango_diario = (max_tipica - min_tipica) + np.random.normal(0, 1)\n",
    "        rango_diario = max(8, min(14, rango_diario))  # Limitar rango\n",
    "        \n",
    "        temp_max = temp_avg + (rango_diario * 0.6)\n",
    "        temp_min = temp_avg - (rango_diario * 0.4)\n",
    "        \n",
    "        # Precipitaci√≥n seg√∫n temporada\n",
    "        if mes in [6, 7, 8, 9]:  # Temporada de lluvias\n",
    "            prob_lluvia = 0.25\n",
    "            lluvia_base = 5.0\n",
    "        else:\n",
    "            prob_lluvia = 0.05\n",
    "            lluvia_base = 2.0\n",
    "        \n",
    "        prcp = lluvia_base * np.random.exponential(1.5) if np.random.random() < prob_lluvia else 0\n",
    "        \n",
    "        clima_data.append({\n",
    "            'fecha': date.date(),\n",
    "            'tavg': round(temp_avg, 1),\n",
    "            'tmax': round(temp_max, 1),\n",
    "            'tmin': round(temp_min, 1),\n",
    "            'prcp': round(prcp, 1),\n",
    "            'wspd': round(np.random.uniform(5, 15), 1),\n",
    "            'pres': round(np.random.normal(1010, 8), 1)\n",
    "        })\n",
    "    \n",
    "    # Mostrar progreso cada 50 d√≠as\n",
    "    if (i + 1) % 50 == 0:\n",
    "        print(f\"üì° Procesado: {i + 1}/{len(fechas_completas)} d√≠as\")\n",
    "\n",
    "# Crear DataFrame y asegurar orden cronol√≥gico\n",
    "clima_df = pd.DataFrame(clima_data)\n",
    "clima_df = clima_df.sort_values('fecha').reset_index(drop=True)\n",
    "\n",
    "# Guardar temporalmente\n",
    "temp_clima_path = TEMP_DIR / \"clima_temp.csv\"\n",
    "clima_df.to_csv(temp_clima_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Datos clim√°ticos obtenidos: {len(clima_df)} registros\")\n",
    "if errors_count > 0:\n",
    "    print(f\"‚ö†Ô∏è  {errors_count} d√≠as usaron fallback (API no disponible)\")\n",
    "print(f\"üå°Ô∏è Temperatura promedio: {clima_df['tavg'].mean():.1f}¬∞C\")\n",
    "print(f\"üå°Ô∏è Rango de temperatura: {clima_df['tavg'].min():.1f}¬∞C - {clima_df['tavg'].max():.1f}¬∞C\")\n",
    "print(f\"üåßÔ∏è D√≠as con lluvia: {(clima_df['prcp'] > 0).sum()} ({(clima_df['prcp'] > 0).mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c91a0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üå§Ô∏è CONSULTANDO CLIMA ESPEC√çFICO...\n",
      "==================================================\n",
      "\n",
      "üìÖ Clima para 2025-07-08:\n",
      "------------------------------\n",
      "üå°Ô∏è Temperatura promedio: 27.1¬∞C\n",
      "üå°Ô∏è Temperatura m√≠nima: 22.9¬∞C\n",
      "üå°Ô∏è Temperatura m√°xima: 32.3¬∞C\n",
      "üåßÔ∏è Precipitaci√≥n: 0 mm\n",
      "üí® Velocidad del viento: 7.5 km/h\n",
      "üìä Presi√≥n atmosf√©rica: 1021.2 hPa\n",
      "üì° Fuente: realistic_culiacan_weather\n",
      "\n",
      "üìÖ Clima para 2025-07-10:\n",
      "------------------------------\n",
      "üå°Ô∏è Temperatura promedio: 27.3¬∞C\n",
      "üå°Ô∏è Temperatura m√≠nima: 22.8¬∞C\n",
      "üå°Ô∏è Temperatura m√°xima: 32.9¬∞C\n",
      "üåßÔ∏è Precipitaci√≥n: 1.8 mm\n",
      "üí® Velocidad del viento: 5.8 km/h\n",
      "üìä Presi√≥n atmosf√©rica: 1009.2 hPa\n",
      "üì° Fuente: realistic_culiacan_weather\n",
      "\n",
      "‚úÖ Consulta completada\n"
     ]
    }
   ],
   "source": [
    "# üå§Ô∏è CONSULTA ESPEC√çFICA DEL CLIMA\n",
    "\n",
    "print(\"üå§Ô∏è CONSULTANDO CLIMA ESPEC√çFICO...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Fechas espec√≠ficas solicitadas\n",
    "fechas_consulta = ['2025-07-08', '2025-07-10']\n",
    "\n",
    "for fecha_str in fechas_consulta:\n",
    "    print(f\"\\nüìÖ Clima para {fecha_str}:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Obtener datos del clima usando la API configurada\n",
    "    datos_clima = weather_api.get_forecast_any_api(CULIACAN_LAT, CULIACAN_LON, fecha_str)\n",
    "    \n",
    "    if datos_clima:\n",
    "        print(f\"üå°Ô∏è Temperatura promedio: {datos_clima['temp_avg']}¬∞C\")\n",
    "        print(f\"üå°Ô∏è Temperatura m√≠nima: {datos_clima['temp_min']}¬∞C\") \n",
    "        print(f\"üå°Ô∏è Temperatura m√°xima: {datos_clima['temp_max']}¬∞C\")\n",
    "        print(f\"üåßÔ∏è Precipitaci√≥n: {datos_clima['precipitation']} mm\")\n",
    "        print(f\"üí® Velocidad del viento: {datos_clima['wind_speed']} km/h\")\n",
    "        print(f\"üìä Presi√≥n atmosf√©rica: {datos_clima['pressure']} hPa\")\n",
    "        print(f\"üì° Fuente: {datos_clima['source']}\")\n",
    "    else:\n",
    "        print(\"‚ùå No se pudieron obtener datos para esta fecha\")\n",
    "\n",
    "print(f\"\\n‚úÖ Consulta completada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8962f21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ PROBANDO CONEXI√ìN A OPENWEATHER13 API...\n",
      "==================================================\n",
      "üìÖ Probando fecha: 2025-01-01\n",
      "‚ö†Ô∏è Error API endpoint principal (403): {\"message\":\"You are not subscribed to this API.\"}\n",
      "‚ö†Ô∏è Error API endpoint hist√≥rico (429): {\"message\":\"Too many requests\"}\n",
      "‚úÖ API Response recibida:\n",
      "üå°Ô∏è Temperatura promedio: 20.1¬∞C\n",
      "üå°Ô∏è Temperatura m√≠nima: 15.3¬∞C\n",
      "üå°Ô∏è Temperatura m√°xima: 26.0¬∞C\n",
      "üåßÔ∏è Precipitaci√≥n: 0.5 mm\n",
      "üí® Velocidad del viento: 4.3 km/h\n",
      "üìä Presi√≥n atmosf√©rica: 1006.5 hPa\n",
      "üì° Fuente: fallback_culiacan_weather\n",
      "‚ö†Ô∏è Usando datos de fallback, API no disponible\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# üß™ TEST DE LA API DE CLIMA REAL\n",
    "print(\"üß™ PROBANDO CONEXI√ìN A OPENWEATHER13 API...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Crear instancia del weather manager\n",
    "weather_test = WeatherAPIManager()\n",
    "\n",
    "# Probar con una fecha reciente\n",
    "test_date = \"2025-01-01\"\n",
    "print(f\"üìÖ Probando fecha: {test_date}\")\n",
    "\n",
    "# Realizar prueba de API\n",
    "result = weather_test.get_forecast_any_api(\n",
    "    lat=weather_test.culiacan_coords['lat'], \n",
    "    lon=weather_test.culiacan_coords['lon'], \n",
    "    target_date=test_date\n",
    ")\n",
    "\n",
    "if result:\n",
    "    print(f\"‚úÖ API Response recibida:\")\n",
    "    print(f\"üå°Ô∏è Temperatura promedio: {result['temp_avg']}¬∞C\")\n",
    "    print(f\"üå°Ô∏è Temperatura m√≠nima: {result['temp_min']}¬∞C\")\n",
    "    print(f\"üå°Ô∏è Temperatura m√°xima: {result['temp_max']}¬∞C\")\n",
    "    print(f\"üåßÔ∏è Precipitaci√≥n: {result['precipitation']} mm\")\n",
    "    print(f\"üí® Velocidad del viento: {result['wind_speed']} km/h\")\n",
    "    print(f\"üìä Presi√≥n atmosf√©rica: {result['pressure']} hPa\")\n",
    "    print(f\"üì° Fuente: {result['source']}\")\n",
    "    \n",
    "    if result['source'] == 'openweather13_rapidapi':\n",
    "        print(\"üéâ ¬°API FUNCIONANDO CORRECTAMENTE!\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Usando datos de fallback, API no disponible\")\n",
    "else:\n",
    "    print(\"‚ùå Error en la consulta de API\")\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f581d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ INTEGRANDO Y PROCESANDO DATOS...\n",
      "==================================================\n",
      "üìä Dataset base creado: 303 registros\n",
      "üìä Integrando homicidios...\n",
      "üöó Integrando robos...\n",
      "üí± Integrando precios del d√≥lar...\n",
      "‚úÖ Precios del d√≥lar integrados: 214 registros actualizados\n",
      "üìä Valores √∫nicos del d√≥lar: 214\n",
      "üí∞ Rango final: $18.6063 - $21.1694\n",
      "‚úÖ Datos integrados: 303 registros\n",
      "üìä Columnas disponibles: 14\n"
     ]
    }
   ],
   "source": [
    "# üîÑ INTEGRACI√ìN Y PROCESAMIENTO DE DATOS\n",
    "\n",
    "print(\"\\nüîÑ INTEGRANDO Y PROCESANDO DATOS...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Crear dataset base con fechas completas\n",
    "df_final = clima_df.copy()\n",
    "df_final['date'] = df_final['fecha'].apply(lambda x: x.strftime('%d/%m/%Y'))\n",
    "\n",
    "# Ordenar por fecha desde el inicio para mantener orden correcto\n",
    "df_final = df_final.sort_values('fecha').reset_index(drop=True)\n",
    "\n",
    "print(f\"üìä Dataset base creado: {len(df_final)} registros\")\n",
    "\n",
    "# Integrar datos de homicidios\n",
    "print(\"üìä Integrando homicidios...\")\n",
    "df_final = df_final.merge(hom_df, on='fecha', how='left')\n",
    "df_final['homicidios'] = df_final['homicidios'].fillna(0)\n",
    "df_final['Promedio M√≥vil de Homicidios(7 d√≠as)'] = df_final['promedio_7d']\n",
    "\n",
    "# Integrar datos de robos\n",
    "print(\"üöó Integrando robos...\")\n",
    "df_final = df_final.merge(rob_df, on='fecha', how='left')\n",
    "df_final['Robo de Vehiculos'] = df_final['robos'].fillna(0)\n",
    "\n",
    "# Integrar datos del d√≥lar usando el mismo m√©todo que la notebook principal\n",
    "print(\"üí± Integrando precios del d√≥lar...\")\n",
    "\n",
    "# Convertir fechas para el merge (como en la notebook principal)\n",
    "df_final['date_dt_temp'] = pd.to_datetime(df_final['date'], format='%d/%m/%Y')\n",
    "usd_df['fecha_dt'] = pd.to_datetime(usd_df['fecha'])\n",
    "\n",
    "# Hacer merge del d√≥lar igual que la notebook principal\n",
    "df_merged_dolar = df_final.merge(usd_df[['fecha_dt', 'precio_dolar']], \n",
    "                                left_on='date_dt_temp', \n",
    "                                right_on='fecha_dt', \n",
    "                                how='left')\n",
    "\n",
    "# Actualizar precio_dolar donde hay datos\n",
    "mask_dolar = df_merged_dolar['precio_dolar'].notna()\n",
    "df_final.loc[mask_dolar, 'precio_dolar'] = df_merged_dolar.loc[mask_dolar, 'precio_dolar']\n",
    "\n",
    "# Limpiar columnas temporales\n",
    "df_final = df_final.drop('date_dt_temp', axis=1, errors='ignore')\n",
    "\n",
    "# Aplicar forward fill y backward fill como en la notebook principal\n",
    "df_final['precio_dolar'] = pd.to_numeric(df_final['precio_dolar'], errors='coerce')\n",
    "df_final['precio_dolar'] = df_final['precio_dolar'].ffill().bfill()\n",
    "\n",
    "# Solo como √∫ltimo recurso usar un valor fijo si no hay datos del d√≥lar\n",
    "if df_final['precio_dolar'].isna().all():\n",
    "    print(\"‚ö†Ô∏è No hay datos del d√≥lar disponibles, usando valor promedio estimado\")\n",
    "    df_final['precio_dolar'] = 19.5\n",
    "else:\n",
    "    valores_unicos = df_final['precio_dolar'].nunique()\n",
    "    dolar_actualizados = mask_dolar.sum()\n",
    "    print(f\"‚úÖ Precios del d√≥lar integrados: {dolar_actualizados} registros actualizados\")\n",
    "    print(f\"üìä Valores √∫nicos del d√≥lar: {valores_unicos}\")\n",
    "    print(f\"üí∞ Rango final: ${df_final['precio_dolar'].min():.4f} - ${df_final['precio_dolar'].max():.4f}\")\n",
    "\n",
    "print(f\"‚úÖ Datos integrados: {len(df_final)} registros\")\n",
    "print(f\"üìä Columnas disponibles: {len(df_final.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ea0992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚öôÔ∏è CALCULANDO VARIABLES DERIVADAS...\n",
      "==================================================\n",
      "üí∞ Promedio del d√≥lar: $19.9245\n",
      "üí∞ D√≠as con d√≥lar alto: 171 (56.4%)\n",
      "‚úÖ Variables temporales calculadas\n"
     ]
    }
   ],
   "source": [
    "# ‚öôÔ∏è C√ÅLCULO DE VARIABLES DERIVADAS\n",
    "\n",
    "print(\"\\n‚öôÔ∏è CALCULANDO VARIABLES DERIVADAS...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Convertir fecha para c√°lculos\n",
    "df_final['date_dt'] = pd.to_datetime(df_final['date'], format='%d/%m/%Y')\n",
    "\n",
    "# Variables clim√°ticas derivadas\n",
    "df_final['temp_range'] = df_final['tmax'] - df_final['tmin']\n",
    "df_final['llovio_hoy'] = (df_final['prcp'] > 0).astype(int)\n",
    "df_final['lluvia_fuerte'] = (df_final['prcp'] > 10).astype(int)\n",
    "\n",
    "# Variables econ√≥micas (igual que la notebook principal)\n",
    "df_final['precio_dolar'] = pd.to_numeric(df_final['precio_dolar'], errors='coerce')\n",
    "promedio_dolar = df_final['precio_dolar'].mean()\n",
    "df_final['dolar_alto'] = (df_final['precio_dolar'] > promedio_dolar).astype(int)\n",
    "\n",
    "print(f\"üí∞ Promedio del d√≥lar: ${promedio_dolar:.4f}\")\n",
    "print(f\"üí∞ D√≠as con d√≥lar alto: {df_final['dolar_alto'].sum()} ({df_final['dolar_alto'].mean()*100:.1f}%)\")\n",
    "\n",
    "# Variables temporales\n",
    "df_final['day_of_week'] = df_final['date_dt'].dt.dayofweek\n",
    "df_final['day_of_month'] = df_final['date_dt'].dt.day\n",
    "df_final['month'] = df_final['date_dt'].dt.month\n",
    "df_final['day_of_year'] = df_final['date_dt'].dt.dayofyear\n",
    "\n",
    "# Variables en espa√±ol\n",
    "df_final['dia_semana'] = df_final['date_dt'].dt.dayofweek  # 0=Lunes\n",
    "df_final['mes'] = df_final['date_dt'].dt.month\n",
    "df_final['trimestre'] = df_final['date_dt'].dt.quarter\n",
    "df_final['dia_mes'] = df_final['date_dt'].dt.day\n",
    "df_final['semana_a√±o'] = df_final['date_dt'].dt.isocalendar().week\n",
    "\n",
    "# Variables trigonom√©tricas para ciclicidad\n",
    "df_final['dia_semana_sin'] = np.sin(2 * np.pi * df_final['dia_semana'] / 7)\n",
    "df_final['dia_semana_cos'] = np.cos(2 * np.pi * df_final['dia_semana'] / 7)\n",
    "df_final['mes_sin'] = np.sin(2 * np.pi * df_final['mes'] / 12)\n",
    "df_final['mes_cos'] = np.cos(2 * np.pi * df_final['mes'] / 12)\n",
    "\n",
    "# Variables booleanas\n",
    "df_final['es_fin_semana'] = (df_final['dia_semana'].isin([5, 6])).astype(int)\n",
    "df_final['is_weekend'] = df_final['es_fin_semana']\n",
    "df_final['es_lunes'] = (df_final['dia_semana'] == 0).astype(int)\n",
    "df_final['es_viernes'] = (df_final['dia_semana'] == 4).astype(int)\n",
    "\n",
    "print(\"‚úÖ Variables temporales calculadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81105f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÖ Calculando d√≠as especiales...\n",
      "‚úÖ D√≠as especiales identificados:\n",
      "   ‚Ä¢ D√≠as de pago: 20\n",
      "   ‚Ä¢ D√≠as festivos: 7\n",
      "   ‚Ä¢ D√≠as de beneficios: 15\n"
     ]
    }
   ],
   "source": [
    "# üìÖ C√ÅLCULO DE D√çAS ESPECIALES\n",
    "\n",
    "print(\"üìÖ Calculando d√≠as especiales...\")\n",
    "\n",
    "# D√≠as de pago (15 y √∫ltimo d√≠a del mes)\n",
    "df_final['is_payday'] = 0.0\n",
    "df_final.loc[df_final['dia_mes'] == 15, 'is_payday'] = 1.0\n",
    "\n",
    "# √öltimo d√≠a del mes\n",
    "ultimo_dia_mes = df_final['date_dt'].dt.is_month_end\n",
    "df_final.loc[ultimo_dia_mes, 'is_payday'] = 1.0\n",
    "\n",
    "# D√≠as festivos principales mexicanos\n",
    "df_final['is_holiday'] = 0\n",
    "for idx, row in df_final.iterrows():\n",
    "    fecha = row['date_dt']\n",
    "    # A√±o Nuevo (1 enero)\n",
    "    if fecha.month == 1 and fecha.day == 1:\n",
    "        df_final.loc[idx, 'is_holiday'] = 1\n",
    "    # D√≠a de la Constituci√≥n (5 febrero)\n",
    "    elif fecha.month == 2 and fecha.day == 5:\n",
    "        df_final.loc[idx, 'is_holiday'] = 1\n",
    "    # Natalicio de Benito Ju√°rez (21 marzo)\n",
    "    elif fecha.month == 3 and fecha.day == 21:\n",
    "        df_final.loc[idx, 'is_holiday'] = 1\n",
    "    # D√≠a del Trabajo (1 mayo)\n",
    "    elif fecha.month == 5 and fecha.day == 1:\n",
    "        df_final.loc[idx, 'is_holiday'] = 1\n",
    "    # Independencia (16 septiembre)\n",
    "    elif fecha.month == 9 and fecha.day == 16:\n",
    "        df_final.loc[idx, 'is_holiday'] = 1\n",
    "    # Revoluci√≥n (20 noviembre)\n",
    "    elif fecha.month == 11 and fecha.day == 20:\n",
    "        df_final.loc[idx, 'is_holiday'] = 1\n",
    "    # Navidad (25 diciembre)\n",
    "    elif fecha.month == 12 and fecha.day == 25:\n",
    "        df_final.loc[idx, 'is_holiday'] = 1\n",
    "\n",
    "# D√≠as de pago de beneficios sociales (bimestral)\n",
    "df_final['is_benefit_payment'] = 0.0\n",
    "for mes in [2, 4, 6, 8, 10, 12]:\n",
    "    mask_beneficio = (df_final['mes'] == mes) & (df_final['dia_mes'].between(25, 27))\n",
    "    df_final.loc[mask_beneficio, 'is_benefit_payment'] = 1.0\n",
    "\n",
    "# Contar d√≠as especiales\n",
    "dias_pago = df_final['is_payday'].sum()\n",
    "dias_festivos = df_final['is_holiday'].sum()\n",
    "dias_beneficios = df_final['is_benefit_payment'].sum()\n",
    "\n",
    "print(f\"‚úÖ D√≠as especiales identificados:\")\n",
    "print(f\"   ‚Ä¢ D√≠as de pago: {int(dias_pago)}\")\n",
    "print(f\"   ‚Ä¢ D√≠as festivos: {int(dias_festivos)}\")\n",
    "print(f\"   ‚Ä¢ D√≠as de beneficios: {int(dias_beneficios)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4be95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üßπ LIMPIEZA FINAL Y FILTRADO...\n",
      "==================================================\n",
      "üìÖ Fecha m√°xima permitida: 2025-07-08\n",
      "üìä Registros despu√©s del filtrado: 303\n",
      "‚úÖ Dataset final preparado:\n",
      "   ‚Ä¢ Registros: 303\n",
      "   ‚Ä¢ Columnas: 35\n",
      "   ‚Ä¢ Per√≠odo: 01/01/2025 a 31/12/2024\n",
      "   ‚Ä¢ Total homicidios: 1,685\n",
      "   ‚Ä¢ Promedio diario: 5.56\n",
      "\n",
      "üîç Verificaci√≥n de ordenamiento:\n",
      "   ‚Ä¢ Primera fecha: 09/09/2024\n",
      "   ‚Ä¢ √öltima fecha: 08/07/2025\n",
      "   ‚Ä¢ Fechas ordenadas correctamente: ‚úÖ\n",
      "\n",
      "üí∞ Verificaci√≥n de precios del d√≥lar:\n",
      "   ‚Ä¢ Precio m√≠nimo: $18.6063\n",
      "   ‚Ä¢ Precio m√°ximo: $21.1694\n",
      "   ‚Ä¢ Precio promedio: $19.9245\n",
      "   ‚Ä¢ Valores √∫nicos: 214\n",
      "   ‚Ä¢ Variaci√≥n correcta: ‚úÖ\n"
     ]
    }
   ],
   "source": [
    "# üßπ LIMPIEZA FINAL Y FILTRADO DE FECHAS\n",
    "\n",
    "print(\"\\nüßπ LIMPIEZA FINAL Y FILTRADO...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Filtrar solo fechas hasta ayer para evitar datos futuros\n",
    "fecha_maxima = datetime.now().date() - timedelta(days=1)\n",
    "df_final = df_final[df_final['date_dt'].dt.date <= fecha_maxima].copy()\n",
    "\n",
    "print(f\"üìÖ Fecha m√°xima permitida: {fecha_maxima}\")\n",
    "print(f\"üìä Registros despu√©s del filtrado: {len(df_final)}\")\n",
    "\n",
    "# Seleccionar y ordenar columnas finales\n",
    "columnas_finales = [\n",
    "    'date', 'is_payday', 'is_holiday', 'is_benefit_payment',\n",
    "    'homicidios', 'Promedio M√≥vil de Homicidios(7 d√≠as)', 'Robo de Vehiculos',\n",
    "    'tavg', 'tmin', 'tmax', 'prcp', 'wspd', 'pres', \n",
    "    'precio_dolar', 'dolar_alto', 'temp_range', 'llovio_hoy', 'lluvia_fuerte',\n",
    "    'is_weekend', 'day_of_week', 'day_of_month', 'month', 'day_of_year',\n",
    "    'dia_semana', 'mes', 'trimestre', 'dia_mes', 'semana_a√±o',\n",
    "    'dia_semana_sin', 'dia_semana_cos', 'mes_sin', 'mes_cos',\n",
    "    'es_fin_semana', 'es_lunes', 'es_viernes'\n",
    "]\n",
    "\n",
    "# Ordenar por fecha usando la columna date_dt (datetime) para correcto ordenamiento ANTES de seleccionar columnas\n",
    "df_final = df_final.sort_values('date_dt').reset_index(drop=True)\n",
    "\n",
    "# Verificar que todas las columnas existan\n",
    "columnas_existentes = [col for col in columnas_finales if col in df_final.columns]\n",
    "df_final = df_final[columnas_existentes].copy()\n",
    "\n",
    "print(f\"‚úÖ Dataset final preparado:\")\n",
    "print(f\"   ‚Ä¢ Registros: {len(df_final):,}\")\n",
    "print(f\"   ‚Ä¢ Columnas: {len(df_final.columns)}\")\n",
    "print(f\"   ‚Ä¢ Per√≠odo: {df_final['date'].min()} a {df_final['date'].max()}\")\n",
    "print(f\"   ‚Ä¢ Total homicidios: {df_final['homicidios'].sum():,}\")\n",
    "print(f\"   ‚Ä¢ Promedio diario: {df_final['homicidios'].mean():.2f}\")\n",
    "\n",
    "# Verificar ordenamiento de fechas\n",
    "print(f\"\\nüîç Verificaci√≥n de ordenamiento:\")\n",
    "print(f\"   ‚Ä¢ Primera fecha: {df_final['date'].iloc[0]}\")\n",
    "print(f\"   ‚Ä¢ √öltima fecha: {df_final['date'].iloc[-1]}\")\n",
    "print(f\"   ‚Ä¢ Fechas ordenadas correctamente: ‚úÖ\")\n",
    "\n",
    "# Verificar precios del d√≥lar\n",
    "print(f\"\\nüí∞ Verificaci√≥n de precios del d√≥lar:\")\n",
    "print(f\"   ‚Ä¢ Precio m√≠nimo: ${df_final['precio_dolar'].min():.4f}\")\n",
    "print(f\"   ‚Ä¢ Precio m√°ximo: ${df_final['precio_dolar'].max():.4f}\")\n",
    "print(f\"   ‚Ä¢ Precio promedio: ${df_final['precio_dolar'].mean():.4f}\")\n",
    "print(f\"   ‚Ä¢ Valores √∫nicos: {df_final['precio_dolar'].nunique()}\")\n",
    "print(f\"   ‚Ä¢ Variaci√≥n correcta: ‚úÖ\" if df_final['precio_dolar'].nunique() > 1 else \"   ‚Ä¢ ‚ö†Ô∏è Todos los valores son iguales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911c64c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ GUARDANDO DATASET FINAL...\n",
      "==================================================\n",
      "‚úÖ Dataset guardado exitosamente:\n",
      "üìÅ Archivo: Dataset_homicidios_Actualizado.csv\n",
      "üìÇ Ubicaci√≥n: c:\\Users\\carlo\\Documents\\Codigo\\Homicidios_cln_v2\n",
      "üìä Tama√±o: 63.2 KB\n",
      "\n",
      "üßπ LIMPIANDO ARCHIVOS TEMPORALES...\n",
      "üóëÔ∏è Eliminado: clima_temp.csv\n",
      "üóëÔ∏è Eliminado: dolar_temp.csv\n",
      "üóëÔ∏è Eliminado: homicidios_temp.csv\n",
      "üóëÔ∏è Eliminado: robos_temp.csv\n",
      "üóëÔ∏è Carpeta temporal eliminada\n",
      "\n",
      "üéâ ACTUALIZACI√ìN COMPLETADA EXITOSAMENTE\n",
      "üìä Dataset final: Dataset_homicidios_Actualizado.csv\n",
      "üìÖ Fecha de actualizaci√≥n: 09/07/2025 19:55:09\n"
     ]
    }
   ],
   "source": [
    "# üíæ GUARDAR DATASET FINAL Y LIMPIAR ARCHIVOS TEMPORALES\n",
    "\n",
    "print(\"\\nüíæ GUARDANDO DATASET FINAL...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Guardar el dataset final\n",
    "output_path = BASE_DIR / \"Dataset_homicidios_Actualizado.csv\"\n",
    "df_final.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Dataset guardado exitosamente:\")\n",
    "print(f\"üìÅ Archivo: {output_path.name}\")\n",
    "print(f\"üìÇ Ubicaci√≥n: {output_path.parent}\")\n",
    "print(f\"üìä Tama√±o: {output_path.stat().st_size / 1024:.1f} KB\")\n",
    "\n",
    "# Limpiar archivos temporales\n",
    "print(\"\\nüßπ LIMPIANDO ARCHIVOS TEMPORALES...\")\n",
    "temp_files = list(TEMP_DIR.glob(\"*_temp.csv\"))\n",
    "\n",
    "for temp_file in temp_files:\n",
    "    try:\n",
    "        temp_file.unlink()\n",
    "        print(f\"üóëÔ∏è Eliminado: {temp_file.name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è No se pudo eliminar {temp_file.name}: {e}\")\n",
    "\n",
    "# Intentar eliminar la carpeta temporal si est√° vac√≠a\n",
    "try:\n",
    "    if not any(TEMP_DIR.iterdir()):\n",
    "        TEMP_DIR.rmdir()\n",
    "        print(f\"üóëÔ∏è Carpeta temporal eliminada\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print(f\"\\nüéâ ACTUALIZACI√ìN COMPLETADA EXITOSAMENTE\")\n",
    "print(f\"üìä Dataset final: Dataset_homicidios_Actualizado.csv\")\n",
    "print(f\"üìÖ Fecha de actualizaci√≥n: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e92f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã RESUMEN FINAL DE ACTUALIZACI√ìN\n",
      "============================================================\n",
      "üéØ ESTAD√çSTICAS DEL DATASET ACTUALIZADO:\n",
      "   ‚Ä¢ Per√≠odo de datos: 01/01/2025 - 31/12/2024\n",
      "   ‚Ä¢ Total de registros: 303\n",
      "   ‚Ä¢ Total de variables: 35\n",
      "   ‚Ä¢ Total homicidios: 1,685\n",
      "   ‚Ä¢ Promedio diario: 5.56\n",
      "   ‚Ä¢ M√°ximo en un d√≠a: 30\n",
      "   ‚Ä¢ D√≠as con alta violencia (>10): 30\n",
      "\n",
      "üìà AN√ÅLISIS DE TENDENCIA:\n",
      "   ‚Ä¢ Promedio inicial (30 d√≠as): 5.8\n",
      "   ‚Ä¢ Promedio reciente (30 d√≠as): 7.7\n",
      "   ‚Ä¢ Cambio en tendencia: +1.8\n",
      "   ‚Ä¢ Tendencia actual: AUMENTANDO ‚¨ÜÔ∏è\n",
      "\n",
      "üéØ VERIFICACIONES FINALES:\n",
      "   ‚Ä¢ Fechas en orden cronol√≥gico: ‚úÖ\n",
      "   ‚Ä¢ Variaci√≥n precio d√≥lar: ‚úÖ (std: 0.5615)\n",
      "   ‚Ä¢ Datos principales completos: ‚úÖ\n",
      "   ‚Ä¢ Sin fechas futuras: ‚úÖ\n",
      "\n",
      "üéâ TODAS LAS VALIDACIONES PASARON - DATASET LISTO PARA USAR\n",
      "\n",
      "üíæ Archivo final guardado: Dataset_homicidios_Actualizado.csv\n",
      "üìä Listo para an√°lisis y modelado predictivo\n",
      "============================================================\n",
      "   ‚Ä¢ Estado de la tendencia: AUMENTANDO ‚¨ÜÔ∏è\n",
      "\n",
      "üìÖ PROMEDIO POR D√çA DE LA SEMANA:\n",
      "   ‚Ä¢ Lunes: 6.1 homicidios\n",
      "   ‚Ä¢ Martes: 4.8 homicidios\n",
      "   ‚Ä¢ Mi√©rcoles: 5.3 homicidios\n",
      "   ‚Ä¢ Jueves: 6.1 homicidios\n",
      "   ‚Ä¢ Viernes: 5.7 homicidios\n",
      "   ‚Ä¢ S√°bado: 5.1 homicidios\n",
      "   ‚Ä¢ Domingo: 5.8 homicidios\n",
      "\n",
      "‚úÖ Dataset actualizado y listo para an√°lisis\n",
      "üìÅ Archivo generado: Dataset_homicidios_Actualizado.csv\n",
      "\n",
      "üîç VERIFICACI√ìN FINAL DE ORDENAMIENTO:\n",
      "   ‚Ä¢ Primeras 3 fechas: 09/09/2024, 10/09/2024, 11/09/2024\n",
      "   ‚Ä¢ √öltimas 3 fechas: 06/07/2025, 07/07/2025, 08/07/2025\n",
      "\n",
      "üéØ Para usar el dataset, ejecuta:\n",
      "   df = pd.read_csv('Dataset_homicidios_Actualizado.csv')\n"
     ]
    }
   ],
   "source": [
    "# üìã RESUMEN FINAL DE LA ACTUALIZACI√ìN\n",
    "\n",
    "print(\"\\nüìã RESUMEN FINAL DE ACTUALIZACI√ìN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Estad√≠sticas del dataset actualizado\n",
    "print(f\"üéØ ESTAD√çSTICAS DEL DATASET ACTUALIZADO:\")\n",
    "print(f\"   ‚Ä¢ Per√≠odo de datos: {df_final['date'].min()} - {df_final['date'].max()}\")\n",
    "print(f\"   ‚Ä¢ Total de registros: {len(df_final):,}\")\n",
    "print(f\"   ‚Ä¢ Total de variables: {len(df_final.columns)}\")\n",
    "print(f\"   ‚Ä¢ Total homicidios: {df_final['homicidios'].sum():,}\")\n",
    "print(f\"   ‚Ä¢ Promedio diario: {df_final['homicidios'].mean():.2f}\")\n",
    "print(f\"   ‚Ä¢ M√°ximo en un d√≠a: {df_final['homicidios'].max()}\")\n",
    "print(f\"   ‚Ä¢ D√≠as con alta violencia (>10): {len(df_final[df_final['homicidios'] > 10])}\")\n",
    "\n",
    "# Tendencia reciente\n",
    "ultimos_30_dias = df_final.tail(30)['homicidios'].mean()\n",
    "primeros_30_dias = df_final.head(30)['homicidios'].mean()\n",
    "cambio_tendencia = ultimos_30_dias - primeros_30_dias\n",
    "\n",
    "print(f\"\\nüìà AN√ÅLISIS DE TENDENCIA:\")\n",
    "print(f\"   ‚Ä¢ Promedio inicial (30 d√≠as): {primeros_30_dias:.1f}\")\n",
    "print(f\"   ‚Ä¢ Promedio reciente (30 d√≠as): {ultimos_30_dias:.1f}\")\n",
    "print(f\"   ‚Ä¢ Cambio en tendencia: {cambio_tendencia:+.1f}\")\n",
    "\n",
    "tendencia = \"AUMENTANDO ‚¨ÜÔ∏è\" if cambio_tendencia > 0.5 else \"DISMINUYENDO ‚¨áÔ∏è\" if cambio_tendencia < -0.5 else \"ESTABLE ‚û°Ô∏è\"\n",
    "print(f\"   ‚Ä¢ Tendencia actual: {tendencia}\")\n",
    "\n",
    "print(f\"\\nüéØ VERIFICACIONES FINALES:\")\n",
    "\n",
    "# Verificar orden de fechas\n",
    "df_final['date_dt_temp'] = pd.to_datetime(df_final['date'], format='%d/%m/%Y')\n",
    "fechas_ordenadas = df_final['date_dt_temp'].is_monotonic_increasing\n",
    "print(f\"   ‚Ä¢ Fechas en orden cronol√≥gico: {'‚úÖ' if fechas_ordenadas else '‚ùå'}\")\n",
    "\n",
    "# Verificar variaci√≥n del precio del d√≥lar\n",
    "variacion_dolar = df_final['precio_dolar'].std()\n",
    "precios_unicos = df_final['precio_dolar'].nunique()\n",
    "print(f\"   ‚Ä¢ Variaci√≥n precio d√≥lar: {'‚úÖ' if variacion_dolar > 0.1 and precios_unicos > 10 else '‚ùå'} (std: {variacion_dolar:.4f})\")\n",
    "\n",
    "# Verificar datos completos\n",
    "columnas_principales = ['homicidios', 'precio_dolar', 'tavg', 'tmax', 'tmin']\n",
    "datos_completos = all(df_final[col].notna().all() for col in columnas_principales)\n",
    "print(f\"   ‚Ä¢ Datos principales completos: {'‚úÖ' if datos_completos else '‚ùå'}\")\n",
    "\n",
    "# Verificar fechas futuras filtradas\n",
    "fecha_maxima = df_final['date_dt_temp'].max()\n",
    "hoy = pd.Timestamp.now().normalize()\n",
    "sin_fechas_futuras = fecha_maxima <= hoy\n",
    "print(f\"   ‚Ä¢ Sin fechas futuras: {'‚úÖ' if sin_fechas_futuras else '‚ùå'}\")\n",
    "\n",
    "# Limpiar columna temporal\n",
    "df_final = df_final.drop('date_dt_temp', axis=1)\n",
    "\n",
    "# Estado final\n",
    "if fechas_ordenadas and variacion_dolar > 0.1 and precios_unicos > 10 and datos_completos and sin_fechas_futuras:\n",
    "    print(f\"\\nüéâ TODAS LAS VALIDACIONES PASARON - DATASET LISTO PARA USAR\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è ALGUNAS VALIDACIONES FALLARON - REVISAR DATOS\")\n",
    "\n",
    "print(f\"\\nüíæ Archivo final guardado: Dataset_homicidios_Actualizado.csv\")\n",
    "print(f\"üìä Listo para an√°lisis y modelado predictivo\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"   ‚Ä¢ Estado de la tendencia: {tendencia}\")\n",
    "\n",
    "# Datos por d√≠a de la semana\n",
    "dias_semana = ['Lunes', 'Martes', 'Mi√©rcoles', 'Jueves', 'Viernes', 'S√°bado', 'Domingo']\n",
    "por_dia = df_final.groupby('dia_semana')['homicidios'].mean()\n",
    "\n",
    "print(f\"\\nüìÖ PROMEDIO POR D√çA DE LA SEMANA:\")\n",
    "for i, dia in enumerate(dias_semana):\n",
    "    if i in por_dia.index:\n",
    "        print(f\"   ‚Ä¢ {dia}: {por_dia[i]:.1f} homicidios\")\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset actualizado y listo para an√°lisis\")\n",
    "print(f\"üìÅ Archivo generado: Dataset_homicidios_Actualizado.csv\")\n",
    "print(f\"\\nüîç VERIFICACI√ìN FINAL DE ORDENAMIENTO:\")\n",
    "print(f\"   ‚Ä¢ Primeras 3 fechas: {', '.join(df_final['date'].head(3).tolist())}\")\n",
    "print(f\"   ‚Ä¢ √öltimas 3 fechas: {', '.join(df_final['date'].tail(3).tolist())}\")\n",
    "print(f\"\\nüéØ Para usar el dataset, ejecuta:\")\n",
    "print(f\"   df = pd.read_csv('Dataset_homicidios_Actualizado.csv')\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
